# Mambaæ¨¡å‹é€‚é…RSSTç®—æ³• - è¯¦ç»†æ–¹æ¡ˆ

**åˆ›å»ºæ—¶é—´**: 2026-01-17  
**åˆ†æ”¯**: `mamba-rsst`  
**çŠ¶æ€**: å¾…å®¡æ ¸

---

## ğŸ“‹ ç›®å½•
1. [èƒŒæ™¯ä¸ç›®æ ‡](#èƒŒæ™¯ä¸ç›®æ ‡)
2. [å½“å‰ä»£ç åº“åˆ†æ](#å½“å‰ä»£ç åº“åˆ†æ)
3. [Mambaæ¨¡å‹æ¶æ„åˆ†æ](#mambaæ¨¡å‹æ¶æ„åˆ†æ)
4. [é€‚é…ç­–ç•¥](#é€‚é…ç­–ç•¥)
5. [å®æ–½è®¡åˆ’ï¼ˆ6ä¸ªé˜¶æ®µï¼‰](#å®æ–½è®¡åˆ’)
6. [æŠ€æœ¯ç»†èŠ‚ä¸æŒ‘æˆ˜](#æŠ€æœ¯ç»†èŠ‚ä¸æŒ‘æˆ˜)
7. [é£é™©ä¸åº”å¯¹](#é£é™©ä¸åº”å¯¹)
8. [éªŒæ”¶æ ‡å‡†](#éªŒæ”¶æ ‡å‡†)

---

## ğŸ¯ èƒŒæ™¯ä¸ç›®æ ‡

### é¡¹ç›®èƒŒæ™¯
- **RSSTç®—æ³•**: Regularized Structured Sparsity Trainingï¼ˆæ­£åˆ™åŒ–ç»“æ„åŒ–ç¨€ç–è®­ç»ƒï¼‰
- **å½“å‰æ”¯æŒæ¨¡å‹**: ResNetç³»åˆ—ã€VGGç³»åˆ—ã€MobileNetç³»åˆ—ã€ViTç³»åˆ—
- **ç›®æ ‡**: å°†RSSTç®—æ³•é€‚é…åˆ°Mambaï¼ˆState Space Modelï¼‰æ¶æ„ä¸Š

### æ ¸å¿ƒç›®æ ‡
1. **åŠŸèƒ½æ€§**: å®ç°Mambaæ¨¡å‹çš„ç»“æ„åŒ–å‰ªæï¼ˆå¤´çº§åˆ«ã€MLPç¥ç»å…ƒçº§åˆ«ï¼‰
2. **ä¸€è‡´æ€§**: ä¿æŒä¸ç°æœ‰ViTå‰ªææµç¨‹çš„ä¸€è‡´æ€§
3. **å…¼å®¹æ€§**: ä¸ç ´åç°æœ‰ä»£ç ï¼Œæ”¯æŒæ— ç¼åˆ‡æ¢
4. **æ€§èƒ½**: éªŒè¯Mamba+RSSTçš„å‰ªææ•ˆæœ

---

## ğŸ“Š å½“å‰ä»£ç åº“åˆ†æ

### 1. æ ¸å¿ƒæ–‡ä»¶ç»“æ„
```
RSST/
â”œâ”€â”€ models/                      # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ vit.py                  # ViTæ¨¡å‹ï¼ˆå‚è€ƒå¯¹è±¡ï¼‰
â”‚   â”œâ”€â”€ resnet.py               # ResNetæ¨¡å‹
â”‚   â””â”€â”€ [å¾…æ·»åŠ ] mamba.py       # Mambaæ¨¡å‹
â”œâ”€â”€ utils.py                     # æ¨¡å‹æ„å»ºå…¥å£ï¼ˆbuild_modelå‡½æ•°ï¼‰
â”œâ”€â”€ main_imp_fillback.py        # ä¸»è®­ç»ƒè„šæœ¬ï¼ˆRefillæ–¹æ³•ï¼‰
â”œâ”€â”€ vit_pruning_utils.py        # ViTä¸“ç”¨å‰ªæå·¥å…·
â”œâ”€â”€ pruning_utils.py            # é€šç”¨å‰ªæå·¥å…·ï¼ˆCNNï¼‰
â””â”€â”€ [å¾…æ·»åŠ ] mamba_pruning_utils.py  # Mambaä¸“ç”¨å‰ªæå·¥å…·
```

### 2. æ¨¡å‹æ³¨å†Œæœºåˆ¶
**ä½ç½®**: `utils.py` çš„ `build_model()` å‡½æ•°

**ç°æœ‰æ¨¡å¼**ï¼ˆä»¥ViTä¸ºä¾‹ï¼‰:
```python
elif args.arch == 'vit_small':
    print('build model: vit_small')
    img_size = 32 if args.dataset in ['cifar10', 'cifar100'] else 64
    pretrained = args.vit_pretrained if hasattr(args, 'vit_pretrained') else False
    model = vit_small(num_classes=classes, img_size=img_size, pretrained=pretrained)
```

**éœ€è¦æ·»åŠ **:
```python
elif args.arch == 'mamba_small':
    print('build model: mamba_small')
    pretrained = args.mamba_pretrained if hasattr(args, 'mamba_pretrained') else False
    model = mamba_small(num_classes=classes, pretrained=pretrained)
```

### 3. å‰ªæå·¥å…·æ¶æ„

#### 3.1 æ¨¡å‹è¯†åˆ«å‡½æ•°
```python
# vit_pruning_utils.py
def is_vit_model(model):
    from models.vit import VisionTransformer
    return isinstance(model, VisionTransformer)
```

**éœ€è¦æ·»åŠ **:
```python
# mamba_pruning_utils.py
def is_mamba_model(model):
    from models.mamba import MambaModel
    return isinstance(model, MambaModel)
```

#### 3.2 å‰ªæå‡½æ•°
**ViTçš„å‰ªææ–¹æ³•**ï¼ˆå‚è€ƒï¼‰:
- `pruning_model_vit(model, px)`: éç»“æ„åŒ–L1å‰ªæ
- `prune_model_custom_vit(model, mask_dict)`: è‡ªå®šä¹‰maskå‰ªæ
- `extract_mask_vit(model)`: æå–å‰ªæmask
- `remove_prune_vit(model)`: ç§»é™¤å‰ªæé’©å­

**Mambaéœ€è¦å®ç°**:
- `pruning_model_mamba(model, px)`: éç»“æ„åŒ–å‰ªæ
- `prune_model_custom_mamba(model, mask_dict)`: è‡ªå®šä¹‰maskå‰ªæ
- `extract_mask_mamba(model)`: æå–mask
- `remove_prune_mamba(model)`: ç§»é™¤é’©å­

### 4. ä¸»è®­ç»ƒè„šæœ¬é›†æˆç‚¹

**å…³é”®ä½ç½®**ï¼ˆ`main_imp_fillback.py`ï¼‰:

1. **å‘½ä»¤è¡Œå‚æ•°** (è¡Œ40-60):
```python
parser.add_argument('--mamba_pretrained', action='store_true', 
                    help='use pretrained model (for Mamba)')
parser.add_argument('--mamba_structured', action='store_true',
                    help='use structured pruning for Mamba')
```

2. **æ¨¡å‹è¯†åˆ«** (è¡Œ308, 359, 448, 497, 618, 648):
```python
if vit_pruning_utils.is_vit_model(model):
    # ViTç‰¹å®šé€»è¾‘
elif mamba_pruning_utils.is_mamba_model(model):
    # Mambaç‰¹å®šé€»è¾‘
else:
    # CNNé»˜è®¤é€»è¾‘
```

3. **å‰ªææ‰§è¡Œ** (è¡Œ359):
```python
if is_mamba:
    mamba_pruning_utils.pruning_model_mamba(model, rate)
```

4. **Maskæå–** (è¡Œ448):
```python
if is_mamba:
    current_mask = mamba_pruning_utils.extract_mask_mamba(model)
```

---

## ğŸ§¬ Mambaæ¨¡å‹æ¶æ„åˆ†æ

### 1. Mambaæ ¸å¿ƒç»„ä»¶

**æ ‡å‡†Mamba Blockç»“æ„**:
```
Input
  â†“
LayerNorm
  â†“
SSM (Selective State Space Module)
  â”œâ”€â”€ Linear Projection (x â†’ B, C, Î”)
  â”œâ”€â”€ Selective Scan (çŠ¶æ€ç©ºé—´è®¡ç®—)
  â””â”€â”€ Output Projection
  â†“
Residual Connection
  â†“
LayerNorm
  â†“
MLP (Feed-Forward)
  â”œâ”€â”€ Linear1 (d_model â†’ mlp_ratio * d_model)
  â”œâ”€â”€ GELU
  â””â”€â”€ Linear2 (mlp_ratio * d_model â†’ d_model)
  â†“
Residual Connection
```

### 2. å¯å‰ªæç»„ä»¶å¯¹æ¯”

| ç»„ä»¶ç±»å‹ | ViT | Mamba | å‰ªæç­–ç•¥ |
|---------|-----|-------|---------|
| **Attention/SSM** | QKV Linear (å¤´çº§åˆ«) | B/C/Î” Linear | **SSMé€šé“çº§åˆ«** |
| **Attention Proj** | Linear (embed_dim â†’ embed_dim) | Output Linear | **é€šé“çº§åˆ«** |
| **MLP FC1** | Linear (dim â†’ mlp_dim) | Linear (d_model â†’ mlp_dim) | **ç¥ç»å…ƒçº§åˆ«** |
| **MLP FC2** | Linear (mlp_dim â†’ dim) | Linear (mlp_dim â†’ d_model) | **ç¥ç»å…ƒçº§åˆ«** |
| **Normå±‚** | LayerNorm | LayerNorm/RMSNorm | **ä¸å‰ªæ** |

### 3. Mambaç‰¹æœ‰è€ƒè™‘

#### 3.1 SSMæ¨¡å—çš„ç‰¹æ®Šæ€§
- **çŠ¶æ€çŸ©é˜µ**: A, B, C, Î”å‚æ•°éœ€è¦ååŒå‰ªæ
- **å·ç§¯è·¯å¾„**: æŸäº›å®ç°æœ‰Conv1Dåˆ†æ”¯ï¼Œéœ€å•ç‹¬å¤„ç†
- **é€‰æ‹©æ€§æœºåˆ¶**: å‰ªæå¯èƒ½å½±å“é€‰æ‹©æ€§é—¨æ§

#### 3.2 ä¸ViTçš„ç›¸ä¼¼æ€§
âœ… **å¯å¤ç”¨çš„éƒ¨åˆ†**:
- MLPæ¨¡å—ç»“æ„å‡ ä¹ç›¸åŒ
- æ®‹å·®è¿æ¥å¤„ç†æ–¹å¼ç±»ä¼¼
- LayerNormä¸éœ€è¦å‰ªæ

âš ï¸ **éœ€è¦ç‰¹æ®Šå¤„ç†**:
- SSMæ›¿ä»£äº†Attentionï¼ˆçº¿æ€§å¤æ‚åº¦ vs äºŒæ¬¡å¤æ‚åº¦ï¼‰
- çŠ¶æ€ç©ºé—´å‚æ•°çš„ä¾èµ–å…³ç³»
- å¯èƒ½çš„æ··åˆæ¶æ„ï¼ˆMamba + Attentionï¼‰

---

## ğŸ”§ é€‚é…ç­–ç•¥

### ç­–ç•¥é€‰æ‹©

**æ–¹æ¡ˆA**: å®Œå…¨æ¨¡ä»¿ViTå‰ªææµç¨‹ï¼ˆæ¨èâœ…ï¼‰
- **ä¼˜ç‚¹**: ä»£ç å¤ç”¨åº¦é«˜ï¼Œé£é™©ä½ï¼Œæ˜“äºç»´æŠ¤
- **ç¼ºç‚¹**: å¯èƒ½æœªå……åˆ†åˆ©ç”¨Mambaçš„ç‰¹æ€§
- **é€‚ç”¨åœºæ™¯**: å¿«é€ŸéªŒè¯ã€å»ºç«‹baseline

**æ–¹æ¡ˆB**: å®šåˆ¶åŒ–Mambaå‰ªæç­–ç•¥
- **ä¼˜ç‚¹**: å¯èƒ½è·å¾—æ›´å¥½æ€§èƒ½
- **ç¼ºç‚¹**: å¼€å‘å‘¨æœŸé•¿ï¼Œé£é™©é«˜
- **é€‚ç”¨åœºæ™¯**: åç»­ä¼˜åŒ–é˜¶æ®µ

**å½“å‰é‡‡ç”¨**: æ–¹æ¡ˆAï¼ˆåç»­å¯è¿­ä»£åˆ°æ–¹æ¡ˆBï¼‰

### å‰ªæç²’åº¦

#### 1. éç»“æ„åŒ–å‰ªæï¼ˆUnstructuredï¼‰
- **ç›®æ ‡**: SSMçš„Linearå±‚ã€MLPçš„Linearå±‚
- **æ–¹æ³•**: å…¨å±€L1å‰ªæ
- **ä¼˜å…ˆçº§**: â­â­â­ (å¿…é¡»å®ç°)

#### 2. ç»“æ„åŒ–å‰ªæï¼ˆStructuredï¼‰
**SSMçº§åˆ«**:
- å‰ªæSSMçš„è¾“å‡ºé€šé“ï¼ˆç±»æ¯”ViTçš„Headï¼‰
- éœ€è¦åŒæ—¶è°ƒæ•´Bã€Cã€Î”çš„ç»´åº¦

**MLPç¥ç»å…ƒçº§åˆ«**:
- å‰ªæMLP FC1çš„è¾“å‡ºç¥ç»å…ƒ
- åŒæ­¥è°ƒæ•´FC2çš„è¾“å…¥ç»´åº¦

**ä¼˜å…ˆçº§**: â­â­ (å®éªŒæ€§åŠŸèƒ½)

---

## ğŸ“… å®æ–½è®¡åˆ’

### é˜¶æ®µ0: å‡†å¤‡å·¥ä½œï¼ˆå½“å‰é˜¶æ®µï¼‰
**æ—¶é—´**: 1å¤©  
**ä»»åŠ¡**:
- [x] åˆ†æç°æœ‰ä»£ç åº“
- [x] åˆ¶å®šé€‚é…æ–¹æ¡ˆ
- [ ] **ç”¨æˆ·å®¡æ ¸æ–¹æ¡ˆ** â¬…ï¸ å½“å‰ä½ç½®
- [ ] ç¡®å®šMambaæ¨¡å‹æ¥æºï¼ˆè‡ªå·±å®ç° vs ä½¿ç”¨å¼€æºåº“ï¼‰

**è¾“å‡º**: æœ¬æ–¹æ¡ˆæ–‡æ¡£

---

### é˜¶æ®µ1: Mambaæ¨¡å‹é›†æˆ
**æ—¶é—´**: 1-2å¤©  
**ä»»åŠ¡**:
1. **è·å–/å®ç°Mambaæ¨¡å‹**
   - é€‰é¡¹A: ä½¿ç”¨ `mamba-ssm` å®˜æ–¹åº“
   - é€‰é¡¹B: å‚è€ƒè®ºæ–‡è‡ªå·±å®ç°
   - é€‰é¡¹C: ä½¿ç”¨ `transformers` åº“çš„Mambaå®ç°

2. **åˆ›å»º `models/mamba.py`**
   ```python
   class MambaModel(nn.Module):
       def __init__(self, d_model, n_layers, num_classes, ...):
           ...
   
   def mamba_small(num_classes=100, pretrained=False):
       return MambaModel(d_model=192, n_layers=24, num_classes=num_classes)
   
   def mamba_base(num_classes=100, pretrained=False):
       return MambaModel(d_model=384, n_layers=24, num_classes=num_classes)
   ```

3. **åœ¨ `utils.py` ä¸­æ³¨å†Œ**
   - æ·»åŠ  `mamba_small`, `mamba_base` ç­‰é€‰é¡¹
   - æ”¯æŒ `--arch mamba_small` å‚æ•°

4. **åŸºç¡€æµ‹è¯•**
   - æµ‹è¯•å‰å‘ä¼ æ’­
   - æµ‹è¯•å‚æ•°æ•°é‡
   - æµ‹è¯•CIFAR-10/100è®­ç»ƒï¼ˆæ— å‰ªæï¼‰

**è¾“å‡º**: 
- `models/mamba.py`
- æµ‹è¯•è„šæœ¬ `test_mamba_model.py`
- åŸºçº¿æ€§èƒ½æŠ¥å‘Š

**éªŒæ”¶æ ‡å‡†**:
- âœ… Mambaæ¨¡å‹å¯ä»¥æ­£å¸¸è®­ç»ƒ
- âœ… åœ¨CIFAR-10è¾¾åˆ°åˆç†ç²¾åº¦ï¼ˆ> 85%ï¼‰
- âœ… æ— å†…å­˜æ³„æ¼æˆ–CUDAé”™è¯¯

---

### é˜¶æ®µ2: å‰ªæå·¥å…·å¼€å‘
**æ—¶é—´**: 2-3å¤©  
**ä»»åŠ¡**:

1. **åˆ›å»º `mamba_pruning_utils.py`**
   
   **æ ¸å¿ƒå‡½æ•°**:
   ```python
   def is_mamba_model(model):
       """åˆ¤æ–­æ˜¯å¦æ˜¯Mambaæ¨¡å‹"""
       
   def pruning_model_mamba(model, px, prune_ssm=True):
       """éç»“æ„åŒ–L1å‰ªæ"""
       # æ”¶é›†å¯å‰ªæå±‚
       # - SSMçš„Linearå±‚
       # - MLPçš„FCå±‚
       
   def prune_model_custom_mamba(model, mask_dict):
       """åº”ç”¨è‡ªå®šä¹‰mask"""
       
   def extract_mask_mamba(model):
       """æå–å½“å‰mask"""
       
   def remove_prune_mamba(model):
       """ç§»é™¤å‰ªæé’©å­"""
       
   def check_sparsity_mamba(model):
       """æ£€æŸ¥ç¨€ç–åº¦"""
   ```

2. **è¯†åˆ«Mambaçš„å¯å‰ªæå±‚**
   - éå†æ¨¡å‹ï¼Œæ‰¾åˆ°æ‰€æœ‰Linearå±‚
   - æ’é™¤åˆ†ç±»å¤´ï¼ˆhead/fcï¼‰
   - æ’é™¤ä½ç½®ç¼–ç ç­‰ç‰¹æ®Šå±‚

3. **å®ç°maskç®¡ç†**
   - ä¸ViTä¿æŒä¸€è‡´çš„maskæ ¼å¼
   - æ”¯æŒcheckpointä¿å­˜/åŠ è½½

4. **å•å…ƒæµ‹è¯•**
   ```python
   # test_mamba_pruning.py
   def test_pruning_functionality():
       model = mamba_small(num_classes=10)
       pruning_model_mamba(model, 0.5)
       sparsity = check_sparsity_mamba(model)
       assert abs(sparsity - 0.5) < 0.01
   ```

**è¾“å‡º**:
- `mamba_pruning_utils.py`
- `test_mamba_pruning.py`
- å•å…ƒæµ‹è¯•æŠ¥å‘Š

**éªŒæ”¶æ ‡å‡†**:
- âœ… æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡
- âœ… å‰ªæåç¨€ç–åº¦ç¬¦åˆé¢„æœŸ
- âœ… maskæå–/åŠ è½½æ­£å¸¸

---

### é˜¶æ®µ3: ä¸»è®­ç»ƒè„šæœ¬é›†æˆ
**æ—¶é—´**: 1-2å¤©  
**ä»»åŠ¡**:

1. **ä¿®æ”¹ `main_imp_fillback.py`**
   
   **æ·»åŠ å‘½ä»¤è¡Œå‚æ•°**:
   ```python
   parser.add_argument('--mamba_pretrained', action='store_true')
   parser.add_argument('--mamba_structured', action='store_true')
   parser.add_argument('--mamba_ssm_prune_ratio', type=float, default=0.0)
   ```

2. **æ·»åŠ æ¨¡å‹åˆ¤æ–­é€»è¾‘**
   
   åœ¨æ‰€æœ‰å…³é”®ä½ç½®ï¼ˆ6å¤„ï¼‰æ·»åŠ Mambaåˆ†æ”¯:
   ```python
   is_vit = vit_pruning_utils.is_vit_model(model)
   is_mamba = mamba_pruning_utils.is_mamba_model(model)
   
   if is_vit:
       # ViTé€»è¾‘
   elif is_mamba:
       # Mambaé€»è¾‘
   else:
       # CNNé€»è¾‘
   ```

3. **é›†æˆå‰ªæè°ƒç”¨**
   ```python
   if is_mamba:
       if args.mamba_structured:
           mamba_pruning_utils.pruning_model_mamba_structured(
               model, rate, args.mamba_ssm_prune_ratio
           )
       else:
           mamba_pruning_utils.pruning_model_mamba(model, rate)
   ```

4. **å¤„ç†checkpointå…¼å®¹æ€§**
   - ç¡®ä¿maskä¿å­˜/åŠ è½½å…¼å®¹
   - é¢„è®­ç»ƒæƒé‡åˆå§‹åŒ–éªŒè¯

**è¾“å‡º**:
- ä¿®æ”¹åçš„ `main_imp_fillback.py`
- é›†æˆæµ‹è¯•è„šæœ¬

**éªŒæ”¶æ ‡å‡†**:
- âœ… å¯ä»¥å¯åŠ¨Mambaè®­ç»ƒ
- âœ… å‰ªææµç¨‹æ­£å¸¸æ‰§è¡Œ
- âœ… checkpointæ­£å¸¸ä¿å­˜/åŠ è½½
- âœ… ä¸å½±å“ViTå’ŒCNNçš„è®­ç»ƒ

---

### é˜¶æ®µ4: å®éªŒéªŒè¯
**æ—¶é—´**: 2-3å¤©  
**ä»»åŠ¡**:

1. **CIFAR-10åŸºç¡€å®éªŒ**
   ```bash
   # æ— å‰ªæbaseline
   python main_imp_fillback.py --arch mamba_small --dataset cifar10 \
       --pruning_times 0 --epochs 160
   
   # 70%éç»“æ„åŒ–å‰ªæ + Refill
   python main_imp_fillback.py --arch mamba_small --dataset cifar10 \
       --rate 0.7 --pruning_times 16 --epochs 60 --fillback_rate 0.0
   
   # 70%éç»“æ„åŒ–å‰ªæ + RSST
   python main_imp_fillback.py --arch mamba_small --dataset cifar10 \
       --rate 0.7 --pruning_times 16 --epochs 60 \
       --reg_granularity_prune 1.0 --RST_schedule exp_custom_exponents \
       --exponents 4
   ```

2. **CIFAR-100éªŒè¯å®éªŒ**
   - é‡å¤CIFAR-10çš„å®éªŒè®¾ç½®

3. **å¯¹æ¯”åˆ†æ**
   - Mamba vs ViT (ç›¸åŒå‰ªæç‡)
   - RSST vs Refill (Mambaä¸Šçš„æ•ˆæœ)
   - ä¸åŒå‰ªæç‡çš„æ€§èƒ½æ›²çº¿

4. **æ€§èƒ½ç›‘æ§**
   - è®­ç»ƒæ—¶é—´
   - GPUæ˜¾å­˜å ç”¨
   - æ¨ç†é€Ÿåº¦ï¼ˆå‰ªæå‰åï¼‰

**è¾“å‡º**:
- å®éªŒç»“æœè¡¨æ ¼
- æ€§èƒ½æ›²çº¿å›¾
- å¯¹æ¯”åˆ†ææŠ¥å‘Š

**éªŒæ”¶æ ‡å‡†**:
- âœ… Mamba+RSSTç²¾åº¦ > Mamba+Refill
- âœ… 70%ç¨€ç–åº¦ä¸‹ç²¾åº¦ä¸‹é™ < 5%
- âœ… è®­ç»ƒè¿‡ç¨‹ç¨³å®šï¼Œæ— å¼‚å¸¸

---

### é˜¶æ®µ5: ç»“æ„åŒ–å‰ªæï¼ˆå¯é€‰ï¼‰
**æ—¶é—´**: 3-4å¤©  
**ä»»åŠ¡**:

1. **SSMé€šé“çº§å‰ªæ**
   - å®ç°SSMè¾“å‡ºé€šé“çš„mask
   - åŠ¨æ€è°ƒæ•´Bã€Cã€Î”ç»´åº¦
   - éªŒè¯çŠ¶æ€ç©ºé—´è®¡ç®—æ­£ç¡®æ€§

2. **MLPç¥ç»å…ƒçº§å‰ªæ**
   - ç±»æ¯”ViTçš„MLPå‰ªæ
   - FC1è¾“å‡º â†’ FC2è¾“å…¥çš„ç»´åº¦åŒæ­¥

3. **æ··åˆå‰ªæç­–ç•¥**
   - `--mamba_prune_target ssm`: ä»…å‰ªæSSM
   - `--mamba_prune_target mlp`: ä»…å‰ªæMLP
   - `--mamba_prune_target both`: ä¸¤è€…éƒ½å‰ªæ

4. **å®éªŒéªŒè¯**
   - å¯¹æ¯”ç»“æ„åŒ– vs éç»“æ„åŒ–
   - æµ‹é‡å®é™…åŠ é€Ÿæ¯”

**è¾“å‡º**:
- ç»“æ„åŒ–å‰ªæå®ç°
- åŠ é€Ÿæµ‹è¯•æŠ¥å‘Š
- æœ€ä½³å®è·µæ–‡æ¡£

**éªŒæ”¶æ ‡å‡†**:
- âœ… ç»“æ„åŒ–å‰ªæåæ¨¡å‹å¯æ­£å¸¸è¿è¡Œ
- âœ… è·å¾—å®é™…æ¨ç†åŠ é€Ÿï¼ˆ> 1.5xï¼‰
- âœ… ç²¾åº¦æŸå¤±å¯æ§

---

### é˜¶æ®µ6: æ–‡æ¡£ä¸æ¸…ç†
**æ—¶é—´**: 1å¤©  
**ä»»åŠ¡**:

1. **ä»£ç æ¸…ç†**
   - ç§»é™¤debugä»£ç 
   - ç»Ÿä¸€å‘½åè§„èŒƒ
   - æ·»åŠ è¯¦ç»†æ³¨é‡Š

2. **æ–‡æ¡£ç¼–å†™**
   ```markdown
   - Mamba_RSSTä½¿ç”¨æŒ‡å—.md
   - Mambaæ¨¡å‹è¯´æ˜.md
   - Mambaå‰ªæAPIæ–‡æ¡£.md
   ```

3. **ç¤ºä¾‹è„šæœ¬**
   ```bash
   run_mamba_rsst.sh
   run_mamba_experiments.sh
   ```

4. **æ›´æ–°ä¸»README**
   - æ·»åŠ Mambaæ”¯æŒè¯´æ˜
   - æ›´æ–°æ¨¡å‹åˆ—è¡¨
   - æ·»åŠ citation

**è¾“å‡º**:
- å®Œæ•´æ–‡æ¡£
- ç¤ºä¾‹è„šæœ¬
- æ›´æ–°çš„README

**éªŒæ”¶æ ‡å‡†**:
- âœ… æ–‡æ¡£æ¸…æ™°æ˜“æ‡‚
- âœ… æ–°ç”¨æˆ·å¯ä»¥å¿«é€Ÿä¸Šæ‰‹
- âœ… æ‰€æœ‰ç¤ºä¾‹å¯è¿è¡Œ

---

## ğŸ”¬ æŠ€æœ¯ç»†èŠ‚ä¸æŒ‘æˆ˜

### æŒ‘æˆ˜1: Mambaæ¨¡å‹æ¥æº

**é€‰é¡¹åˆ†æ**:

| é€‰é¡¹ | ä¼˜ç‚¹ | ç¼ºç‚¹ | æ¨èåº¦ |
|-----|------|------|--------|
| **mamba-ssmå®˜æ–¹åº“** | é«˜è´¨é‡å®ç°ã€æ€§èƒ½ä¼˜åŒ–å¥½ | ä¾èµ–CUDA kernelsã€å¯èƒ½ä¸æ˜“ä¿®æ”¹ | â­â­â­â­ |
| **transformersåº“** | æ˜“é›†æˆã€æ–‡æ¡£å®Œå–„ | å¯èƒ½ç¼ºå°‘æŸäº›åŠŸèƒ½ | â­â­â­â­ |
| **è‡ªå·±å®ç°** | å®Œå…¨å¯æ§ã€æ˜“äºå‰ªæ | å¼€å‘æˆæœ¬é«˜ã€å¯èƒ½æœ‰bug | â­â­ |

**å»ºè®®**: ä¼˜å…ˆä½¿ç”¨ `mamba-ssm` æˆ– `transformers`ï¼Œå°è£…ä¸€å±‚wrapperä¾¿äºå‰ªæã€‚

### æŒ‘æˆ˜2: SSMæ¨¡å—çš„å‰ªæ

**é—®é¢˜**: SSMçš„Bã€Cã€Î”å‚æ•°ç›¸äº’ä¾èµ–

**è§£å†³æ–¹æ¡ˆ**:
1. **éç»“æ„åŒ–å‰ªæ**: ç›´æ¥å¯¹Linearå±‚æƒé‡å‰ªæï¼ˆä¸ViTä¸€è‡´ï¼‰
2. **ç»“æ„åŒ–å‰ªæ**: éœ€è¦ååŒè°ƒæ•´å¤šä¸ªå‚æ•°çŸ©é˜µçš„ç»´åº¦

```python
# ä¼ªä»£ç 
def prune_ssm_channel(ssm_module, channel_mask):
    # channel_mask: [d_state] bool tensor
    ssm_module.B = ssm_module.B[:, channel_mask]
    ssm_module.C = ssm_module.C[channel_mask, :]
    ssm_module.delta_proj.weight = ssm_module.delta_proj.weight[channel_mask, :]
```

### æŒ‘æˆ˜3: ä¸åŒMambaå˜ä½“

**Mamba-1 vs Mamba-2**:
- Mamba-2å¼•å…¥äº†æ›´å¤šä¼˜åŒ–ï¼ˆSSDã€åˆ†ç»„ç­‰ï¼‰
- éœ€è¦ç¡®ä¿å‰ªæé€»è¾‘å…¼å®¹ä¸åŒç‰ˆæœ¬

**åº”å¯¹**: 
- ä»Mamba-1å¼€å§‹
- é¢„ç•™æ‰©å±•æ¥å£

### æŒ‘æˆ˜4: é¢„è®­ç»ƒæ¨¡å‹

**é—®é¢˜**: Mambaåœ¨CIFAR-10/100ä¸Šæ²¡æœ‰å®˜æ–¹é¢„è®­ç»ƒæ¨¡å‹

**åº”å¯¹**:
1. ä»éšæœºåˆå§‹åŒ–å¼€å§‹ï¼ˆä¸ViTæ— é¢„è®­ç»ƒæ¨¡å¼ä¸€è‡´ï¼‰
2. åç»­å¯è‡ªå·±åœ¨ImageNetä¸Šé¢„è®­ç»ƒ
3. æˆ–ä½¿ç”¨transfer learning

---

## âš ï¸ é£é™©ä¸åº”å¯¹

| é£é™© | æ¦‚ç‡ | å½±å“ | åº”å¯¹æªæ–½ |
|-----|------|------|----------|
| **Mambaåº“ä¾èµ–å†²çª** | ä¸­ | é«˜ | åˆ›å»ºç‹¬ç«‹condaç¯å¢ƒï¼Œå›ºå®šç‰ˆæœ¬ |
| **CUDA kernelä¸å…¼å®¹** | ä½ | é«˜ | ä½¿ç”¨çº¯PyTorchå®ç°çš„Mamba |
| **å‰ªæåç²¾åº¦å´©æºƒ** | ä¸­ | ä¸­ | ä»ä½å‰ªæç‡å¼€å§‹ï¼Œé€æ­¥å¢åŠ  |
| **å†…å­˜æº¢å‡º** | ä½ | ä¸­ | å‡å°batch sizeï¼Œä½¿ç”¨gradient checkpointing |
| **è®­ç»ƒä¸ç¨³å®š** | ä¸­ | ä¸­ | è°ƒæ•´å­¦ä¹ ç‡ã€warmupã€æ­£åˆ™åŒ– |
| **ä¸ç°æœ‰ä»£ç å†²çª** | ä½ | é«˜ | å……åˆ†æµ‹è¯•ï¼Œä½¿ç”¨åˆ†æ”¯éš”ç¦» |

---

## âœ… éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½æ€§éªŒæ”¶
- [ ] Mambaæ¨¡å‹å¯ä»¥ç‹¬ç«‹è®­ç»ƒï¼ˆæ— å‰ªæï¼‰
- [ ] éç»“æ„åŒ–å‰ªæåŠŸèƒ½æ­£å¸¸
- [ ] RSSTæ­£åˆ™åŒ–æ­£å¸¸å·¥ä½œ
- [ ] checkpointä¿å­˜/åŠ è½½æ­£å¸¸
- [ ] ä¸å½±å“ç°æœ‰ViT/ResNetåŠŸèƒ½

### æ€§èƒ½éªŒæ”¶
- [ ] CIFAR-10 baselineç²¾åº¦ > 85%
- [ ] 70%ç¨€ç–åº¦ç²¾åº¦ä¸‹é™ < 5%
- [ ] RSSTä¼˜äºRefillï¼ˆè‡³å°‘+1%ï¼‰
- [ ] è®­ç»ƒæ—¶é—´å¢åŠ  < 20%

### ä»£ç è´¨é‡
- [ ] æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡
- [ ] æ— linteré”™è¯¯
- [ ] ä»£ç è¦†ç›–ç‡ > 80%
- [ ] æ–‡æ¡£å®Œæ•´æ¸…æ™°

### å¯æ‰©å±•æ€§
- [ ] æ˜“äºæ·»åŠ æ–°çš„Mambaå˜ä½“
- [ ] æ˜“äºè°ƒæ•´å‰ªæç­–ç•¥
- [ ] æ˜“äºé›†æˆåˆ°å…¶ä»–é¡¹ç›®

---

## ğŸ“ å¼€å‘æ£€æŸ¥æ¸…å•

### é˜¶æ®µ0: å‡†å¤‡
- [x] åˆ†æç°æœ‰ä»£ç åº“
- [x] æ’°å†™æ–¹æ¡ˆæ–‡æ¡£
- [ ] ç”¨æˆ·å®¡æ ¸é€šè¿‡
- [ ] ç¡®å®šMambaæ¥æº
- [ ] åˆ›å»ºå¼€å‘åˆ†æ”¯

### é˜¶æ®µ1: æ¨¡å‹é›†æˆ
- [ ] å®ç°/é›†æˆMambaæ¨¡å‹
- [ ] åœ¨utils.pyæ³¨å†Œ
- [ ] åŸºç¡€è®­ç»ƒæµ‹è¯•
- [ ] æ€§èƒ½baselineæµ‹è¯•

### é˜¶æ®µ2: å‰ªæå·¥å…·
- [ ] åˆ›å»ºmamba_pruning_utils.py
- [ ] å®ç°is_mamba_model
- [ ] å®ç°pruning_model_mamba
- [ ] å®ç°extract_mask_mamba
- [ ] å®ç°remove_prune_mamba
- [ ] å•å…ƒæµ‹è¯•

### é˜¶æ®µ3: ä¸»è„šæœ¬é›†æˆ
- [ ] æ·»åŠ å‘½ä»¤è¡Œå‚æ•°
- [ ] é›†æˆæ¨¡å‹åˆ¤æ–­é€»è¾‘
- [ ] é›†æˆå‰ªæè°ƒç”¨
- [ ] checkpointå…¼å®¹æ€§æµ‹è¯•

### é˜¶æ®µ4: å®éªŒéªŒè¯
- [ ] CIFAR-10 baseline
- [ ] CIFAR-10 + Refill
- [ ] CIFAR-10 + RSST
- [ ] CIFAR-100å®éªŒ
- [ ] æ€§èƒ½å¯¹æ¯”åˆ†æ

### é˜¶æ®µ5: ç»“æ„åŒ–å‰ªæï¼ˆå¯é€‰ï¼‰
- [ ] SSMé€šé“çº§å‰ªæ
- [ ] MLPç¥ç»å…ƒçº§å‰ªæ
- [ ] æ··åˆå‰ªæç­–ç•¥
- [ ] åŠ é€ŸéªŒè¯

### é˜¶æ®µ6: æ”¶å°¾
- [ ] ä»£ç æ¸…ç†
- [ ] æ–‡æ¡£ç¼–å†™
- [ ] ç¤ºä¾‹è„šæœ¬
- [ ] READMEæ›´æ–°
- [ ] åˆå¹¶åˆ°ä¸»åˆ†æ”¯

---

## ğŸ“ å‚è€ƒèµ„æ–™

### è®ºæ–‡
1. **Mamba**: [Mamba: Linear-Time Sequence Modeling with Selective State Spaces](https://arxiv.org/abs/2312.00752)
2. **RSSTåŸè®ºæ–‡**: Coarsening the Granularity: Towards Structurally Sparse Lottery Tickets
3. **LTH**: The Lottery Ticket Hypothesis

### ä»£ç å‚è€ƒ
1. **mamba-ssm**: https://github.com/state-spaces/mamba
2. **transformers Mamba**: https://huggingface.co/docs/transformers/model_doc/mamba
3. **å½“å‰é¡¹ç›®ViTå®ç°**: `models/vit.py`, `vit_pruning_utils.py`

---

## ğŸ’¬ å¾…è®¨è®ºé—®é¢˜

è¯·å®¡æ ¸ä»¥ä¸‹é—®é¢˜å¹¶ç»™å‡ºåé¦ˆï¼š

1. **Mambaæ¨¡å‹æ¥æº**: æ‚¨å€¾å‘äºä½¿ç”¨å“ªä¸ªMambaå®ç°ï¼Ÿ
   - [ ] mamba-ssmå®˜æ–¹åº“
   - [ ] transformersåº“
   - [ ] è‡ªå·±å®ç°ç®€åŒ–ç‰ˆ
   - [ ] å…¶ä»–: __________

2. **æ•°æ®é›†é€‰æ‹©**: é™¤äº†CIFAR-10/100ï¼Œæ˜¯å¦éœ€è¦ImageNetå®éªŒï¼Ÿ
   - [ ] ä»…CIFARå³å¯
   - [ ] éœ€è¦ImageNet
   - [ ] å…ˆCIFARï¼Œåç»­è€ƒè™‘ImageNet

3. **ä¼˜å…ˆçº§**: éç»“æ„åŒ– vs ç»“æ„åŒ–å‰ªæï¼Ÿ
   - [ ] ä¼˜å…ˆéç»“æ„åŒ–ï¼ˆå¿«é€ŸéªŒè¯ï¼‰
   - [ ] ä¼˜å…ˆç»“æ„åŒ–ï¼ˆå®é™…åŠ é€Ÿï¼‰
   - [ ] ä¸¤è€…å¹¶è¡Œ

4. **æ—¶é—´é¢„æœŸ**: æ•´ä½“å¼€å‘å‘¨æœŸï¼Ÿ
   - [ ] 1å‘¨ï¼ˆæœ€å°å¯è¡Œç‰ˆæœ¬ï¼‰
   - [ ] 2å‘¨ï¼ˆå®Œæ•´åŠŸèƒ½ï¼‰
   - [ ] 1ä¸ªæœˆï¼ˆåŒ…æ‹¬å……åˆ†å®éªŒï¼‰

5. **å…¶ä»–éœ€æ±‚**: è¿˜æœ‰ä»€ä¹ˆç‰¹æ®Šè¦æ±‚æˆ–å…³æ³¨ç‚¹ï¼Ÿ
   - ______________________

---

**è¯·å®¡æ ¸æ­¤æ–¹æ¡ˆï¼Œç¡®è®¤åæˆ‘ä»¬å¼€å§‹å®æ–½ï¼** ğŸš€
