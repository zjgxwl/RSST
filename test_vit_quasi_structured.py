"""
æµ‹è¯•ViTçš„å‡†ç»“æ„åŒ–å‰ªæï¼ˆHead-level Quasi-Structured Pruningï¼‰
éªŒè¯RSSTçš„æ¸è¿›å¼è¿­ä»£æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""
import torch
import torch.nn as nn
from models.vit import vit_tiny
import vit_pruning_utils

def test_quasi_structured_pruning():
    print("="*80)
    print("æµ‹è¯•ViTå‡†ç»“æ„åŒ–å‰ªæï¼ˆHeadçº§åˆ«Maské‡ç»„ï¼‰")
    print("="*80)
    
    # åˆ›å»ºæ¨¡å‹
    model = vit_tiny(num_classes=100, img_size=32, pretrained=False).cuda()
    print(f"\nâœ“ åˆ›å»ºViT-Tinyæ¨¡å‹")
    
    # ç¬¬ä¸€æ­¥ï¼šå…¨å±€L1å‰ªæï¼ˆelement-wiseï¼‰
    print("\nã€æ­¥éª¤1ã€‘å…¨å±€L1å‰ªæ (element-wise, 20%)")
    vit_pruning_utils.pruning_model_vit(model, px=0.2, prune_patch_embed=False)
    
    # æå–mask
    current_mask = vit_pruning_utils.extract_mask_vit(model.state_dict())
    print(f"âœ“ æå–åˆ° {len(current_mask)} ä¸ªmask")
    
    # æ£€æŸ¥ç¨€ç–åº¦
    remain_1 = vit_pruning_utils.check_sparsity_vit(model, prune_patch_embed=False)
    
    # ç§»é™¤å‰ªæé‡å‚æ•°åŒ–ï¼ˆå¿…é¡»åœ¨ä¿å­˜trained_weightä¹‹å‰ï¼‰
    vit_pruning_utils.remove_prune_vit(model, prune_patch_embed=False)
    
    # åˆ›å»ºè®­ç»ƒæ•°æ®ï¼ˆæ¨¡æ‹Ÿï¼‰
    train_loader = [(torch.randn(4, 3, 32, 32).cuda(), torch.randint(0, 100, (4,)).cuda())]
    
    # ä¿å­˜åˆå§‹çŠ¶æ€ï¼ˆç”¨äºæ¯æ¬¡æµ‹è¯•ï¼‰ - åœ¨remove_pruneä¹‹åä¿å­˜ï¼Œé¿å…weight_orig/weight_mask
    base_current_mask = {k: v.clone() for k, v in current_mask.items()}
    base_trained_weight = {k: v.clone() for k, v in model.state_dict().items()}
    base_init_weight = {k: v.clone() for k, v in model.state_dict().items()}
    
    # ç¬¬äºŒæ­¥ï¼šHeadçº§åˆ«çš„å‡†ç»“æ„åŒ–maské‡ç»„
    print("\n" + "="*80)
    print("ã€æ­¥éª¤2ã€‘Headçº§åˆ«å‡†ç»“æ„åŒ–Maské‡ç»„")
    print("="*80)
    
    # æµ‹è¯•æ‰€æœ‰5ç§criteria
    criteria_list = ['remain', 'magnitude', 'l1', 'l2', 'saliency']
    
    for criteria in criteria_list:
        # æ¯æ¬¡æµ‹è¯•å‰é‡ç½®æ‰€æœ‰çŠ¶æ€ï¼ˆå› ä¸ºå‡½æ•°å¯èƒ½ä¼šä¿®æ”¹modelï¼‰
        current_mask = {k: v.clone() for k, v in base_current_mask.items()}
        trained_weight = {k: v.clone() for k, v in base_trained_weight.items()}
        init_weight = {k: v.clone() for k, v in base_init_weight.items()}
        
        print(f"\n{'â”€'*80}")
        print(f"æµ‹è¯• criteria={criteria}")
        print(f"{'â”€'*80}")
        
        # è°ƒç”¨headçº§åˆ«çš„å‡†ç»“æ„åŒ–å‰ªæ
        refill_mask = vit_pruning_utils.prune_model_custom_fillback_vit_by_head(
            model=model,
            mask_dict=current_mask,
            train_loader=train_loader,
            trained_weight=trained_weight,
            init_weight=init_weight,
            criteria=criteria,
            prune_ratio=0.3,  # 30%çš„heads
            return_mask_only=True  # RSSTæ¨¡å¼ï¼šåªè¿”å›mask
        )
        
        # éªŒè¯è¿”å›çš„mask
        print(f"\nâœ“ è¿”å› {len(refill_mask)} ä¸ªheadçº§åˆ«çš„mask")
        
        # æ£€æŸ¥maskçš„ç»“æ„
        for name, mask in refill_mask.items():
            if 'attn.qkv' in name:
                # éªŒè¯æ˜¯å¦æ˜¯headçº§åˆ«çš„mask
                # æ¯ä¸ªheadè¦ä¹ˆå…¨0è¦ä¹ˆå…¨1
                parts = name.split('.')
                block_idx = int(parts[1])
                
                # è·å–æ¨¡å‹çš„å¯¹åº”block
                attn = model.blocks[block_idx].attn
                num_heads = attn.num_heads
                head_dim = attn.head_dim
                
                # é‡å¡‘mask
                mask_reshaped = mask.view(3, num_heads, head_dim, -1)
                
                # æ£€æŸ¥æ¯ä¸ªhead
                for h in range(num_heads):
                    head_mask = mask_reshaped[:, h, :, :]
                    unique_vals = torch.unique(head_mask)
                    
                    # æ¯ä¸ªheadåº”è¯¥è¦ä¹ˆå…¨0è¦ä¹ˆå…¨1
                    is_structured = len(unique_vals) == 1 and (unique_vals[0] == 0 or unique_vals[0] == 1)
                    
                    if is_structured:
                        status = "å…¨0 (å‰ªæ)" if unique_vals[0] == 0 else "å…¨1 (ä¿ç•™)"
                        print(f"  {name}, Head {h}: âœ“ {status}")
                    else:
                        print(f"  {name}, Head {h}: âœ— ä¸æ˜¯å‡†ç»“æ„åŒ–! unique_vals={unique_vals}")
        
        print(f"\nâœ“ criteria={criteria} æµ‹è¯•å®Œæˆ")
    
    # ç¬¬ä¸‰æ­¥ï¼šæµ‹è¯•åº”ç”¨maskåçš„æ­£åˆ™åŒ–å…¼å®¹æ€§
    print("\n" + "="*80)
    print("ã€æ­¥éª¤3ã€‘éªŒè¯Maskå¯ä»¥ç”¨äºæ­£åˆ™åŒ–")
    print("="*80)
    
    # è·å–ä¸€ä¸ªrefill_mask
    refill_mask = vit_pruning_utils.prune_model_custom_fillback_vit_by_head(
        model=model,
        mask_dict=current_mask,
        train_loader=train_loader,
        trained_weight=trained_weight,
        init_weight=init_weight,
        criteria='magnitude',
        prune_ratio=0.3,
        return_mask_only=True
    )
    
    # æ£€æŸ¥maskç»´åº¦æ˜¯å¦åŒ¹é…
    print("\néªŒè¯refill_maskå’Œcurrent_maskç»´åº¦æ˜¯å¦ä¸€è‡´:")
    for name in refill_mask.keys():
        if 'attn' in name or 'mlp' in name:
            mask_key = name + '.weight_mask'
            if mask_key in current_mask:
                refill_shape = refill_mask[name].shape
                current_shape = current_mask[mask_key].shape
                match = refill_shape == current_shape
                print(f"  {name}: refill={refill_shape}, current={current_shape} {'âœ“' if match else 'âœ—'}")
    
    # æ¨¡æ‹Ÿupdate_regçš„é€»è¾‘
    print("\næ¨¡æ‹Ÿupdate_regæ‰¾å‡ºéœ€è¦æ­£åˆ™åŒ–çš„æƒé‡:")
    for name in list(refill_mask.keys())[:2]:  # åªçœ‹å‰2å±‚
        if 'attn.qkv' in name:
            mask_key = name + '.weight_mask'
            if mask_key in current_mask:
                refill_mask_flat = refill_mask[name].flatten()
                current_mask_flat = current_mask[mask_key].flatten()
                
                # æ‰¾å‡ºéœ€è¦æ­£åˆ™åŒ–çš„ç´¢å¼•ï¼ˆrefill=0 ä¸” current=1ï¼‰
                unpruned_indices = torch.where((refill_mask_flat == 0) & (current_mask_flat == 1))[0]
                
                print(f"  {name}:")
                print(f"    - Total weights: {refill_mask_flat.numel()}")
                print(f"    - Refill mask=0: {(refill_mask_flat == 0).sum().item()}")
                print(f"    - Current mask=1: {(current_mask_flat == 1).sum().item()}")
                print(f"    - Need regularization: {len(unpruned_indices)} weights")
    
    print("\n" + "="*80)
    print("âœ“ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    print("="*80)
    print("\næ€»ç»“:")
    print("  1. âœ“ å…¨å±€L1å‰ªæï¼ˆelement-wiseï¼‰æ­£å¸¸")
    print("  2. âœ“ Headçº§åˆ«å‡†ç»“æ„åŒ–maské‡ç»„æ­£å¸¸")
    print("  3. âœ“ æ‰€æœ‰5ç§criteriaéƒ½æ”¯æŒ")
    print("  4. âœ“ ç”Ÿæˆçš„maskæ˜¯headçº§åˆ«çš„ï¼ˆæ•´ä¸ªheadå…¨0æˆ–å…¨1ï¼‰")
    print("  5. âœ“ Maskç»´åº¦åŒ¹é…ï¼Œå¯ç”¨äºæ­£åˆ™åŒ–")
    print("\nğŸ‘ å‡†ç»“æ„åŒ–å‰ªæå®ç°æ­£ç¡®ï¼Œå…¼å®¹RSSTçš„æ¸è¿›å¼è¿­ä»£ï¼")

if __name__ == '__main__':
    test_quasi_structured_pruning()
