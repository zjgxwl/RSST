# æ¨¡åž‹æ›¿æ¢å’Œå‰ªæžä¿®æ”¹å®žæˆ˜ç¤ºä¾‹

## ðŸ“ ç›®å½•
1. [æ¨¡åž‹æ›¿æ¢å®Œæ•´ç¤ºä¾‹](#ä¸€æ¨¡åž‹æ›¿æ¢å®Œæ•´ç¤ºä¾‹)
2. [å‰ªæžæ–¹æ³•ä¿®æ”¹ç¤ºä¾‹](#äºŒå‰ªæžæ–¹æ³•ä¿®æ”¹ç¤ºä¾‹)
3. [å‚æ•°è°ƒä¼˜æŒ‡å—](#ä¸‰å‚æ•°è°ƒä¼˜æŒ‡å—)
4. [å®žéªŒå¯¹æ¯”ç¤ºä¾‹](#å››å®žéªŒå¯¹æ¯”ç¤ºä¾‹)

---

## ä¸€ã€æ¨¡åž‹æ›¿æ¢å®Œæ•´ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šå°†ResNet20æ›¿æ¢ä¸ºResNet32

#### æ­¥éª¤1ï¼šåˆ›å»ºæ¨¡åž‹æ–‡ä»¶
åˆ›å»º `models/resnet32.py`ï¼š

```python
import torch
import torch.nn as nn

class BasicBlock32(nn.Module):
    expansion = 1

    def __init__(self, in_planes, planes, stride=1):
        super(BasicBlock32, self).__init__()
        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, 
                               stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, 
                               stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(planes)

        self.shortcut = nn.Sequential()
        if stride != 1 or in_planes != self.expansion*planes:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_planes, self.expansion*planes, 
                         kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(self.expansion*planes)
            )

    def forward(self, x):
        out = torch.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += self.shortcut(x)
        out = torch.relu(out)
        return out

class ResNet32(nn.Module):
    def __init__(self, block, num_blocks, num_classes=100):
        super(ResNet32, self).__init__()
        self.in_planes = 16

        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, 
                               stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(16)
        
        # ResNet32: [5, 5, 5] blocks
        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)
        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)
        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)
        
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(64*block.expansion, num_classes)

    def _make_layer(self, block, planes, num_blocks, stride):
        strides = [stride] + [1]*(num_blocks-1)
        layers = []
        for stride in strides:
            layers.append(block(self.in_planes, planes, stride))
            self.in_planes = planes * block.expansion
        return nn.Sequential(*layers)

    def forward(self, x):
        out = torch.relu(self.bn1(self.conv1(x)))
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.avgpool(out)
        out = out.view(out.size(0), -1)
        out = self.fc(out)
        return out

def resnet32(num_classes=100):
    return ResNet32(BasicBlock32, [5, 5, 5], num_classes=num_classes)
```

#### æ­¥éª¤2ï¼šä¿®æ”¹utils.py
åœ¨ `utils.py` å¼€å¤´æ·»åŠ å¯¼å…¥ï¼š

```python
# utils.py ç¬¬1-16è¡Œä¹‹é—´æ·»åŠ 
from models.resnet32 import resnet32
```

åœ¨ `setup_model_dataset()` å‡½æ•°ä¸­æ·»åŠ é€‰é¡¹ï¼š

```python
# utils.py ç¬¬96è¡ŒåŽæ·»åŠ 
elif args.arch == 'res32s':
    print('build model: resnet32')
    model = resnet32(number_class=classes)
```

#### æ­¥éª¤3ï¼šè¿è¡Œ
```bash
python main_imp_fillback.py \
    --arch res32s \
    --dataset cifar100 \
    --struct rsst \
    --pruning_times 20 \
    --rate 0.2 \
    --epochs 120
```

---

### ç¤ºä¾‹2ï¼šæ·»åŠ è‡ªå®šä¹‰VGGå˜ç§

#### æ­¥éª¤1ï¼šåˆ›å»ºæ¨¡åž‹ `models/my_vgg.py`

```python
import torch.nn as nn

class MyVGG(nn.Module):
    def __init__(self, num_classes=100):
        super(MyVGG, self).__init__()
        
        # ç‰¹å¾æå–å±‚
        self.features = nn.Sequential(
            # Block 1
            nn.Conv2d(3, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            # Block 2
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            # Block 3
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        
        # åˆ†ç±»å±‚
        self.classifier = nn.Sequential(
            nn.Linear(256 * 4 * 4, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(512, num_classes),
        )
        
    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

def my_vgg(num_classes=100):
    return MyVGG(num_classes=num_classes)
```

#### æ­¥éª¤2ï¼šé›†æˆåˆ°utils.py

```python
# å¯¼å…¥
from models.my_vgg import my_vgg

# æ·»åŠ é€‰é¡¹
elif args.arch == 'my_vgg':
    print('build model: my_vgg')
    model = my_vgg(num_classes=classes)
```

#### æ­¥éª¤3ï¼šè¿è¡Œ
```bash
python main_imp_fillback.py --arch my_vgg --dataset cifar100
```

---

### ç¤ºä¾‹3ï¼šä½¿ç”¨é¢„è®­ç»ƒæ¨¡åž‹ï¼ˆtorchvisionï¼‰

#### ä¿®æ”¹utils.pyæ·»åŠ é¢„è®­ç»ƒResNet50

```python
# utils.py å¯¼å…¥éƒ¨åˆ†
import torchvision.models as tv_models

# setup_model_dataset() å‡½æ•°ä¸­æ·»åŠ 
elif args.arch == 'pretrained_resnet50':
    print('build model: pretrained ResNet50')
    model = tv_models.resnet50(pretrained=True)
    
    # ä¿®æ”¹ç¬¬ä¸€å±‚ï¼ˆé€‚é…CIFARçš„32x32è¾“å…¥ï¼‰
    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, 
                           padding=1, bias=False)
    model.maxpool = nn.Identity()  # ç§»é™¤maxpool
    
    # ä¿®æ”¹åˆ†ç±»å±‚
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, classes)
```

**æ³¨æ„äº‹é¡¹ï¼š**
- é¢„è®­ç»ƒæ¨¡åž‹éœ€è¦è°ƒæ•´å­¦ä¹ çŽ‡ï¼ˆå»ºè®®0.001ï¼‰
- ç¬¬ä¸€å±‚å·ç§¯ä¸è¦å‰ªæžï¼ˆ`--conv1` ä¸è¦è®¾ç½®ï¼‰
- è€ƒè™‘ä½¿ç”¨ä¸åŒçš„ä¼˜åŒ–å™¨ï¼ˆå¦‚Adamï¼‰

---

## äºŒã€å‰ªæžæ–¹æ³•ä¿®æ”¹ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šä¿®æ”¹å…¨å±€å‰ªæžä¸ºé€å±‚å‰ªæž

#### åŽŸå§‹ä»£ç ï¼ˆå…¨å±€L1å‰ªæžï¼‰
`pruning_utils.py` ç¬¬6-22è¡Œï¼š

```python
def pruning_model(model, px, conv1=False):
    parameters_to_prune = []
    for name, m in model.named_modules():
        if isinstance(m, nn.Conv2d):
            if (name == 'conv1' and conv1) or (name != 'conv1'):
                parameters_to_prune.append((m,'weight'))
    
    parameters_to_prune = tuple(parameters_to_prune)
    
    # å…¨å±€å‰ªæž
    prune.global_unstructured(
        parameters_to_prune,
        pruning_method=prune.L1Unstructured,
        amount=px,
    )
```

#### ä¿®æ”¹ä¸ºé€å±‚å‰ªæž

```python
def pruning_model_layerwise(model, px, conv1=False):
    """
    é€å±‚å‰ªæžï¼šæ¯å±‚ç‹¬ç«‹å‰ªæžpxæ¯”ä¾‹
    """
    print('start layerwise pruning for all conv layers')
    
    for name, m in model.named_modules():
        if isinstance(m, nn.Conv2d):
            if (name == 'conv1' and conv1) or (name != 'conv1'):
                # é€å±‚å‰ªæž
                prune.l1_unstructured(
                    m,
                    name='weight',
                    amount=px,
                )
                print(f"Pruned layer {name}: {px*100}%")
```

#### åœ¨main_imp_fillback.pyä¸­ä½¿ç”¨

```python
# ç¬¬321è¡Œæ”¹ä¸º
from pruning_utils import pruning_model_layerwise
pruning_model_layerwise(model, args.rate, conv1=False)
```

---

### ç¤ºä¾‹2ï¼šå®žçŽ°ç»“æž„åŒ–å‰ªæžï¼ˆFilter Pruningï¼‰

#### æ·»åŠ åˆ°pruning_utils.py

```python
def pruning_model_structured(model, px, conv1=False):
    """
    ç»“æž„åŒ–å‰ªæžï¼šç§»é™¤æ•´ä¸ªfilter
    """
    import torch.nn.utils.prune as prune
    
    print('start structured pruning for all conv layers')
    
    for name, m in model.named_modules():
        if isinstance(m, nn.Conv2d):
            if (name == 'conv1' and conv1) or (name != 'conv1'):
                # è®¡ç®—æ¯ä¸ªfilterçš„L1èŒƒæ•°
                filter_norms = m.weight.data.abs().view(m.weight.size(0), -1).sum(1)
                
                # æ‰¾åˆ°è¦å‰ªæžçš„filteræ•°é‡
                num_filters = m.weight.size(0)
                num_prune = int(num_filters * px)
                
                if num_prune > 0:
                    # é€‰æ‹©L1èŒƒæ•°æœ€å°çš„filters
                    _, indices = torch.sort(filter_norms)
                    prune_indices = indices[:num_prune]
                    
                    # åˆ›å»ºmaskï¼ˆæ•´ä¸ªfilterç½®ä¸º0ï¼‰
                    mask = torch.ones_like(m.weight)
                    mask[prune_indices] = 0
                    
                    # åº”ç”¨mask
                    prune.custom_from_mask(m, 'weight', mask)
                    
                    print(f"Layer {name}: pruned {num_prune}/{num_filters} filters")

def check_sparsity_structured(model, conv1=False):
    """
    æ£€æŸ¥ç»“æž„åŒ–ç¨€ç–åº¦ï¼ˆfilterçº§åˆ«ï¼‰
    """
    total_filters = 0
    zero_filters = 0
    
    for name, m in model.named_modules():
        if isinstance(m, nn.Conv2d):
            if (name == 'conv1' and not conv1):
                continue
            
            # è®¡ç®—æ¯ä¸ªfilterçš„L1èŒƒæ•°
            filter_norms = m.weight.data.abs().view(m.weight.size(0), -1).sum(1)
            total_filters += m.weight.size(0)
            zero_filters += (filter_norms == 0).sum().item()
    
    print(f'Structured sparsity: {zero_filters}/{total_filters} filters removed')
    print(f'Remaining filters: {100*(1-zero_filters/total_filters):.2f}%')
    
    return 100*(1-zero_filters/total_filters)
```

---

### ç¤ºä¾‹3ï¼šæ·»åŠ è‡ªå®šä¹‰criteria - ä½¿ç”¨Hessianä¿¡æ¯

#### åœ¨pruning_utils.pyæ·»åŠ æ–°çš„criteria

```python
def compute_hessian_importance(model, train_loader, criterion):
    """
    è®¡ç®—åŸºäºŽHessiançš„é‡è¦æ€§åˆ†æ•°
    """
    model.eval()
    scores = {}
    
    # èŽ·å–ä¸€ä¸ªbatchçš„æ•°æ®
    images, targets = next(iter(train_loader))
    images, targets = images.cuda(), targets.cuda()
    
    # å‰å‘+åå‘èŽ·å–ä¸€é˜¶æ¢¯åº¦
    output = model(images)
    loss = criterion(output, targets)
    loss.backward(create_graph=True)
    
    for name, m in model.named_modules():
        if isinstance(m, nn.Conv2d) and name != 'conv1':
            # ä¸€é˜¶å¯¼æ•°
            grad = m.weight.grad
            
            # è®¡ç®—Hessianå¯¹è§’çº¿è¿‘ä¼¼ï¼ˆäºŒé˜¶å¯¼æ•°ï¼‰
            grad_vec = grad.view(-1)
            hessian_diag = []
            
            for i in range(min(100, len(grad_vec))):  # é‡‡æ ·ä»¥èŠ‚çœæ—¶é—´
                grad2 = torch.autograd.grad(
                    grad_vec[i], m.weight, 
                    retain_graph=True, 
                    create_graph=False
                )[0]
                hessian_diag.append(grad2.view(-1)[i].item())
            
            # é‡è¦æ€§ = |weight| * |hessian|
            importance = m.weight.data.abs() * torch.tensor(hessian_diag).mean()
            scores[name] = importance
    
    return scores
```

#### åœ¨prune_model_custom_fillbackä¸­æ·»åŠ æ–°criteria

```python
# pruning_utils.py ç¬¬77è¡Œå‡½æ•°ä¸­æ·»åŠ 
elif criteria == 'hessian':
    mask = mask_dict[name+'.weight_mask']
    
    # è®¡ç®—Hessiané‡è¦æ€§
    hessian_scores = compute_hessian_importance(model, train_loader, criterion)
    count = hessian_scores[name].view(mask.shape[0], -1).sum(1)
    
    threshold, _ = torch.kthvalue(count, mask.shape[0] - int_channel)
    mask[torch.where(count > threshold)[0]] = 1
    mask[torch.where(count < threshold)[0]] = 0
```

---

### ç¤ºä¾‹4ï¼šå®žçŽ°æ¸è¿›å¼å‰ªæžï¼ˆProgressive Pruningï¼‰

#### ä¿®æ”¹main_imp_fillback.pyçš„å‰ªæžçŽ‡

```python
# åœ¨main_imp_fillback.pyç¬¬321è¡Œå‰æ·»åŠ 
# æ¸è¿›å¼å‰ªæžï¼šå‰ªæžçŽ‡éšstateå¢žåŠ è€Œå‡å°
if state < 5:
    current_rate = args.rate  # å‰5è½®ï¼š20%
elif state < 10:
    current_rate = args.rate * 0.8  # 5-10è½®ï¼š16%
elif state < 15:
    current_rate = args.rate * 0.6  # 10-15è½®ï¼š12%
else:
    current_rate = args.rate * 0.4  # 15+è½®ï¼š8%

print(f"State {state}: using pruning rate = {current_rate}")
pruning_model(model, current_rate, conv1=False)
```

---

## ä¸‰ã€å‚æ•°è°ƒä¼˜æŒ‡å—

### 3.1 RSSTæ ¸å¿ƒå‚æ•°è°ƒä¼˜

#### å‚æ•°1ï¼šreg_granularity_pruneï¼ˆæ­£åˆ™åŒ–ç²’åº¦ï¼‰

```bash
# æ¸©å’Œå‰ªæžï¼ˆæŽ¨èæ–°æ¨¡åž‹ï¼‰
python main_imp_fillback.py --reg_granularity_prune 0.5

# æ ‡å‡†å‰ªæžï¼ˆé»˜è®¤ï¼‰
python main_imp_fillback.py --reg_granularity_prune 1.0

# æ¿€è¿›å‰ªæžï¼ˆé«˜åŽ‹ç¼©çŽ‡ï¼‰
python main_imp_fillback.py --reg_granularity_prune 2.0
```

**æ•ˆæžœï¼š**
- å€¼è¶Šå°ï¼šæ­£åˆ™åŒ–å¢žé•¿è¶Šæ…¢ï¼Œå‰ªæžè¶Šæ¸©å’Œï¼Œç²¾åº¦ä¿æŒæ›´å¥½
- å€¼è¶Šå¤§ï¼šæ­£åˆ™åŒ–å¢žé•¿è¶Šå¿«ï¼Œå‰ªæžè¶Šæ¿€è¿›ï¼ŒåŽ‹ç¼©çŽ‡æ›´é«˜

#### å‚æ•°2ï¼šRST_scheduleï¼ˆæ­£åˆ™åŒ–å¢žé•¿ç­–ç•¥ï¼‰

```bash
# çº¿æ€§å¢žé•¿ï¼ˆæœ€æ¸©å’Œï¼‰
python main_imp_fillback.py --RST_schedule x

# äºŒæ¬¡å¢žé•¿
python main_imp_fillback.py --RST_schedule x^2

# æŒ‡æ•°å¢žé•¿ï¼ˆæ¿€è¿›ï¼‰
python main_imp_fillback.py --RST_schedule exp

# è‡ªå®šä¹‰æŒ‡æ•°ï¼ˆæŽ¨èï¼Œå¯æŽ§ï¼‰
python main_imp_fillback.py --RST_schedule exp_custom_exponents --exponents 4
```

**exponentså‚æ•°å¯¹æ¯”ï¼š**
```bash
--exponents 2  # å¢žé•¿ç¼“æ…¢ï¼Œé€‚åˆå°æ¨¡åž‹
--exponents 4  # é»˜è®¤ï¼Œå¹³è¡¡
--exponents 6  # å¢žé•¿å¿«é€Ÿï¼Œé€‚åˆå¤§æ¨¡åž‹
```

#### å‚æ•°3ï¼šcriteriaï¼ˆé‡è¦æ€§è¯„ä¼°æ ‡å‡†ï¼‰

```bash
# L1èŒƒæ•°ï¼ˆæŽ¨èï¼Œå¿«é€Ÿï¼‰
python main_imp_fillback.py --criteria l1

# æƒé‡å¹…åº¦ï¼ˆç»å…¸ï¼‰
python main_imp_fillback.py --criteria magnitude

# L2èŒƒæ•°ï¼ˆç¨³å®šï¼‰
python main_imp_fillback.py --criteria l2

# æ˜¾è‘—æ€§ï¼ˆç²¾ç»†ï¼Œæ…¢ï¼‰
python main_imp_fillback.py --criteria saliency
```

### 3.2 è®­ç»ƒå‚æ•°è°ƒä¼˜

#### å­¦ä¹ çŽ‡è°ƒä¼˜

```bash
# å°æ¨¡åž‹ï¼ˆResNet20ï¼‰
python main_imp_fillback.py --lr 0.01 --decreasing_lr 91,136

# å¤§æ¨¡åž‹ï¼ˆResNet50ï¼‰
python main_imp_fillback.py --lr 0.1 --decreasing_lr 30,60,90

# é¢„è®­ç»ƒæ¨¡åž‹å¾®è°ƒ
python main_imp_fillback.py --lr 0.001 --decreasing_lr 60,80
```

#### Batch sizeè°ƒä¼˜

```bash
# å°æ¨¡åž‹/å°GPU
python main_imp_fillback.py --batch_size 128

# æ ‡å‡†é…ç½®
python main_imp_fillback.py --batch_size 256

# å¤§GPU/å¿«é€Ÿè®­ç»ƒ
python main_imp_fillback.py --batch_size 512
```

### 3.3 å‰ªæžç­–ç•¥è°ƒä¼˜

#### å‰ªæžçŽ‡å’Œæ¬¡æ•°

```bash
# æ–¹æ¡ˆ1ï¼šæ¿€è¿›å‰ªæžï¼ˆæœ€ç»ˆ1%ï¼‰
python main_imp_fillback.py --pruning_times 20 --rate 0.2
# å‰©ä½™çŽ‡: 0.8^20 â‰ˆ 1.15%

# æ–¹æ¡ˆ2ï¼šæ¸©å’Œå‰ªæžï¼ˆæœ€ç»ˆ10%ï¼‰
python main_imp_fillback.py --pruning_times 15 --rate 0.15
# å‰©ä½™çŽ‡: 0.85^15 â‰ˆ 8.74%

# æ–¹æ¡ˆ3ï¼šä¿å®ˆå‰ªæžï¼ˆæœ€ç»ˆ20%ï¼‰
python main_imp_fillback.py --pruning_times 10 --rate 0.15
# å‰©ä½™çŽ‡: 0.85^10 â‰ˆ 19.69%
```

#### Rewind epochè°ƒä¼˜

```bash
# Early rewindï¼ˆé€‚åˆæµ…å±‚ç½‘ç»œï¼‰
python main_imp_fillback.py --rewind_epoch 10 --prune_type rewind_lt

# Standard rewindï¼ˆé»˜è®¤ï¼‰
python main_imp_fillback.py --rewind_epoch 24 --prune_type rewind_lt

# Late rewindï¼ˆé€‚åˆæ·±å±‚ç½‘ç»œï¼‰
python main_imp_fillback.py --rewind_epoch 40 --prune_type rewind_lt
```

---

## å››ã€å®žéªŒå¯¹æ¯”ç¤ºä¾‹

### 4.1 å¯¹æ¯”å®žéªŒè„šæœ¬

#### å®žéªŒ1ï¼šRSST vs Refill vs IMP

```bash
# 1. æ ‡å‡†IMPï¼ˆLottery Ticketï¼‰
python main_imp_fillback.py \
    --arch res20s --dataset cifar100 \
    --struct refill --fillback_rate 0.0 \
    --save_dir results/imp_baseline

# 2. Refillï¼ˆ10%æ¢å¤ï¼‰
python main_imp_fillback.py \
    --arch res20s --dataset cifar100 \
    --struct refill --fillback_rate 0.1 \
    --criteria l1 \
    --save_dir results/refill_l1_10

# 3. RSSTï¼ˆçº¿æ€§scheduleï¼‰
python main_imp_fillback.py \
    --arch res20s --dataset cifar100 \
    --struct rsst \
    --RST_schedule x \
    --reg_granularity_prune 1.0 \
    --save_dir results/rsst_linear

# 4. RSSTï¼ˆæŒ‡æ•°scheduleï¼‰
python main_imp_fillback.py \
    --arch res20s --dataset cifar100 \
    --struct rsst \
    --RST_schedule exp_custom_exponents \
    --exponents 4 \
    --reg_granularity_prune 1.0 \
    --save_dir results/rsst_exp4
```

#### å®žéªŒ2ï¼šä¸åŒcriteriaå¯¹æ¯”

```bash
for criteria in remain magnitude l1 l2 saliency; do
    python main_imp_fillback.py \
        --arch res20s --dataset cifar100 \
        --struct refill \
        --criteria $criteria \
        --fillback_rate 0.1 \
        --save_dir results/refill_${criteria}
done
```

#### å®žéªŒ3ï¼šä¸åŒæ¨¡åž‹å¯¹æ¯”

```bash
for arch in res20s res56s vgg16_bn mobilenet; do
    python main_imp_fillback.py \
        --arch $arch --dataset cifar100 \
        --struct rsst \
        --save_dir results/${arch}_rsst
done
```

### 4.2 ç»“æžœåˆ†æžè„šæœ¬

åˆ›å»º `analyze_results.py`ï¼š

```python
import os
import torch
import matplotlib.pyplot as plt
import pandas as pd

def load_checkpoint(path):
    """åŠ è½½checkpointå¹¶æå–å…³é”®ä¿¡æ¯"""
    ckpt = torch.load(path, map_location='cpu')
    return {
        'state': ckpt.get('state', 0),
        'epoch': ckpt.get('epoch', 0),
        'best_acc': ckpt.get('best_sa', 0),
        'train_acc': ckpt['result']['train'][-1] if 'result' in ckpt else 0,
        'test_acc': ckpt['result']['test_ta'][-1] if 'result' in ckpt else 0,
    }

def compare_experiments(exp_dirs):
    """æ¯”è¾ƒå¤šä¸ªå®žéªŒç»“æžœ"""
    results = []
    
    for exp_dir in exp_dirs:
        # æ‰¾åˆ°æœ€ä½³checkpoint
        best_ckpt = os.path.join(exp_dir, '19model_SA_best.pth.tar')
        if os.path.exists(best_ckpt):
            info = load_checkpoint(best_ckpt)
            info['exp_name'] = os.path.basename(exp_dir)
            results.append(info)
    
    # åˆ›å»ºDataFrame
    df = pd.DataFrame(results)
    print(df.to_string())
    
    # ç»˜åˆ¶å¯¹æ¯”å›¾
    plt.figure(figsize=(10, 6))
    plt.bar(df['exp_name'], df['test_acc'])
    plt.ylabel('Test Accuracy (%)')
    plt.title('Experiment Comparison')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('experiment_comparison.png')
    print("Saved comparison plot to experiment_comparison.png")

if __name__ == '__main__':
    exp_dirs = [
        'results/imp_baseline',
        'results/refill_l1_10',
        'results/rsst_linear',
        'results/rsst_exp4',
    ]
    compare_experiments(exp_dirs)
```

è¿è¡Œåˆ†æžï¼š
```bash
python analyze_results.py
```

### 4.3 å¯è§†åŒ–å‰ªæžè¿‡ç¨‹

åˆ›å»º `visualize_pruning.py`ï¼š

```python
import torch
import matplotlib.pyplot as plt
import numpy as np

def plot_sparsity_evolution(checkpoint_dir, save_path='sparsity_evolution.png'):
    """ç»˜åˆ¶ç¨€ç–åº¦æ¼”åŒ–æ›²çº¿"""
    states = range(20)
    sparsities = []
    test_accs = []
    
    for state in states:
        ckpt_path = f"{checkpoint_dir}/{state}checkpoint.pth.tar"
        if not os.path.exists(ckpt_path):
            continue
            
        ckpt = torch.load(ckpt_path, map_location='cpu')
        
        # è®¡ç®—ç¨€ç–åº¦
        total = 0
        zeros = 0
        for name, param in ckpt['state_dict'].items():
            if 'weight' in name and 'conv' in name:
                total += param.numel()
                zeros += (param == 0).sum().item()
        
        sparsity = zeros / total * 100
        sparsities.append(sparsity)
        
        # èŽ·å–æµ‹è¯•ç²¾åº¦
        test_acc = ckpt['result']['test_ta'][-1] if 'result' in ckpt else 0
        test_accs.append(test_acc)
    
    # ç»˜å›¾
    fig, ax1 = plt.subplots(figsize=(10, 6))
    
    ax1.plot(range(len(sparsities)), sparsities, 'b-o', label='Sparsity')
    ax1.set_xlabel('Pruning Iteration')
    ax1.set_ylabel('Sparsity (%)', color='b')
    ax1.tick_params(axis='y', labelcolor='b')
    
    ax2 = ax1.twinx()
    ax2.plot(range(len(test_accs)), test_accs, 'r-s', label='Test Acc')
    ax2.set_ylabel('Test Accuracy (%)', color='r')
    ax2.tick_params(axis='y', labelcolor='r')
    
    fig.tight_layout()
    plt.title('Sparsity vs Accuracy Evolution')
    plt.savefig(save_path)
    print(f"Saved plot to {save_path}")

if __name__ == '__main__':
    plot_sparsity_evolution('results/rsst_exp4')
```

---

## äº”ã€å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### é—®é¢˜1ï¼šOOMï¼ˆæ˜¾å­˜ä¸è¶³ï¼‰

**ç—‡çŠ¶ï¼š** `RuntimeError: CUDA out of memory`

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# æ–¹æ¡ˆ1ï¼šå‡å°batch size
python main_imp_fillback.py --batch_size 64

# æ–¹æ¡ˆ2ï¼šä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
# ä¿®æ”¹trainå‡½æ•°ï¼Œæ·»åŠ ï¼š
if (i + 1) % accumulation_steps == 0:
    optimizer.step()
    optimizer.zero_grad()

# æ–¹æ¡ˆ3ï¼šä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
# åœ¨trainå‡½æ•°ä¸­ä½¿ç”¨torch.cuda.amp
```

### é—®é¢˜2ï¼šè®­ç»ƒç²¾åº¦ä¸‹é™è¿‡å¿«

**ç—‡çŠ¶ï¼š** å‰ªæžåŽç²¾åº¦å¤§å¹…ä¸‹é™

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# æ–¹æ¡ˆ1ï¼šé™ä½Žå‰ªæžçŽ‡
python main_imp_fillback.py --rate 0.15  # ä»Ž0.2é™åˆ°0.15

# æ–¹æ¡ˆ2ï¼šä½¿ç”¨æ¸©å’Œçš„schedule
python main_imp_fillback.py --RST_schedule x

# æ–¹æ¡ˆ3ï¼šå¢žåŠ è®­ç»ƒè½®æ•°
python main_imp_fillback.py --epochs 160

# æ–¹æ¡ˆ4ï¼šä½¿ç”¨Refillæ¢å¤éƒ¨åˆ†æƒé‡
python main_imp_fillback.py --struct refill --fillback_rate 0.2
```

### é—®é¢˜3ï¼šæ­£åˆ™åŒ–ä¸ç”Ÿæ•ˆ

**ç—‡çŠ¶ï¼š** RSSTå’ŒIMPæ•ˆæžœç›¸åŒ

**æ£€æŸ¥æ¸…å•ï¼š**
```python
# 1. ç¡®è®¤passer.refill_maskä¸ä¸ºç©º
print("refill_mask:", passer.refill_mask is not None)

# 2. ç¡®è®¤update_regè¢«è°ƒç”¨
# åœ¨main_imp_fillback.pyç¬¬432è¡Œæ·»åŠ ï¼š
print(f"Calling update_reg at batch {i}")

# 3. ç¡®è®¤æ­£åˆ™åŒ–å¼ºåº¦ä¸ä¸º0
# åœ¨apply_regå‡½æ•°ä¸­æ·»åŠ ï¼š
print(f"reg stats: min={reg.min()}, max={reg.max()}, mean={reg.mean()}")

# 4. ç¡®è®¤æ¢¯åº¦è¢«ä¿®æ”¹
# åœ¨apply_regåŽæ·»åŠ ï¼š
for name, param in model.named_parameters():
    if param.grad is not None:
        print(f"{name} grad norm: {param.grad.norm()}")
```

### é—®é¢˜4ï¼šä¸åŒå®žéªŒç»“æžœä¸å¯å¤çŽ°

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# è®¾ç½®éšæœºç§å­
python main_imp_fillback.py --seed 42

# ç¦ç”¨cudnnçš„éžç¡®å®šæ€§ç®—æ³•
# åœ¨mainå‡½æ•°å¼€å¤´æ·»åŠ ï¼š
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
```

---

## å…­ã€é«˜çº§æŠ€å·§

### æŠ€å·§1ï¼šåŠ¨æ€è°ƒæ•´æ­£åˆ™åŒ–å¼ºåº¦

ä¿®æ”¹ `update_reg()` å‡½æ•°ï¼š

```python
def update_reg_dynamic(passer, pruner, model, state, i, j, current_acc, target_acc):
    """
    æ ¹æ®å½“å‰ç²¾åº¦åŠ¨æ€è°ƒæ•´æ­£åˆ™åŒ–å¼ºåº¦
    """
    # å¦‚æžœç²¾åº¦ä½ŽäºŽç›®æ ‡ï¼Œå‡å°æ­£åˆ™åŒ–
    if current_acc < target_acc:
        scale = 0.5
    else:
        scale = 1.0
    
    for name, m in model.named_modules():
        if isinstance(m, nn.Conv2d) and name != 'conv1':
            # ... åŽŸæœ‰ä»£ç  ...
            weight_start *= scale  # åº”ç”¨ç¼©æ”¾å› å­
            pruner.reg[name][unpruned_indices_np] = weight_start
```

### æŠ€å·§2ï¼šåˆ†ç»„å‰ªæžï¼ˆä¸åŒå±‚ä¸åŒå‰ªæžçŽ‡ï¼‰

```python
def get_layer_specific_rate(name, base_rate):
    """
    ä¸ºä¸åŒå±‚åˆ†é…ä¸åŒçš„å‰ªæžçŽ‡
    """
    if 'layer1' in name:
        return base_rate * 0.5  # æµ…å±‚å°‘å‰ª
    elif 'layer2' in name:
        return base_rate * 1.0  # ä¸­å±‚æ­£å¸¸å‰ª
    elif 'layer3' in name:
        return base_rate * 1.5  # æ·±å±‚å¤šå‰ª
    else:
        return base_rate

# åœ¨pruning_modelä¸­ä½¿ç”¨
for name, m in model.named_modules():
    if isinstance(m, nn.Conv2d):
        layer_rate = get_layer_specific_rate(name, args.rate)
        prune.l1_unstructured(m, 'weight', amount=layer_rate)
```

### æŠ€å·§3ï¼šçŸ¥è¯†è’¸é¦è¾…åŠ©å‰ªæž

```python
def train_with_distillation(student, teacher, train_loader, criterion, 
                           optimizer, alpha=0.5, temperature=3.0):
    """
    ä½¿ç”¨çŸ¥è¯†è’¸é¦è®­ç»ƒè¢«å‰ªæžçš„æ¨¡åž‹
    """
    teacher.eval()
    student.train()
    
    for images, targets in train_loader:
        images, targets = images.cuda(), targets.cuda()
        
        # Teacherè¾“å‡º
        with torch.no_grad():
            teacher_outputs = teacher(images)
        
        # Studentè¾“å‡º
        student_outputs = student(images)
        
        # ç¡¬æ ‡ç­¾æŸå¤±
        loss_hard = criterion(student_outputs, targets)
        
        # è½¯æ ‡ç­¾æŸå¤±ï¼ˆKLæ•£åº¦ï¼‰
        loss_soft = nn.KLDivLoss()(
            F.log_softmax(student_outputs / temperature, dim=1),
            F.softmax(teacher_outputs / temperature, dim=1)
        ) * (temperature ** 2)
        
        # æ€»æŸå¤±
        loss = alpha * loss_hard + (1 - alpha) * loss_soft
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

---

**æ–‡æ¡£ç‰ˆæœ¬ï¼š** v1.0  
**æœ€åŽæ›´æ–°ï¼š** 2026-01-05  
**ä½œè€…å»ºè®®ï¼š** å»ºè®®ä»Žç®€å•ç¤ºä¾‹å¼€å§‹ï¼Œé€æ­¥å°è¯•é«˜çº§åŠŸèƒ½

