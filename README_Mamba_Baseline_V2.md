# ğŸš€ Mamba-Small Baseline V2 å¿«é€Ÿå‚è€ƒ

> å…¨é¢ä¼˜åŒ–ç‰ˆï¼Œç²¾åº¦ +2-6%ï¼Œé€Ÿåº¦ 2-3Ã—

---

## âš¡ ä¸€é”®å¯åŠ¨

```bash
cd /workspace/ycx/RSST
./run_mamba_baseline_v2.sh
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| ç‰ˆæœ¬ | CIFAR-10 | CIFAR-100 | è®­ç»ƒæ—¶é—´ |
|-----|----------|-----------|---------|
| **V1** | 94-95.5% | 76-81% | 2-3 å¤© |
| **V2** | **97-98%** â¬†ï¸ | **82-86%** â¬†ï¸ | **1-1.5 å¤©** â¬‡ï¸ |

---

## âœ… V2 æ–°å¢ä¼˜åŒ–ï¼ˆ10é¡¹ï¼‰

### æ€§èƒ½ä¼˜åŒ–
1. âœ… Drop Path (0.1) â†’ +0.5-1%
2. âœ… EMA (0.9999) â†’ +0.3-0.7%
3. âœ… AutoAugment â†’ +0.5-1%
4. âœ… Random Erasing â†’ +0.3-0.5%
5. âœ… Layer-wise LR â†’ +0.3-0.5%
6. âœ… Gradient Clipping â†’ ç¨³å®šæ€§
7. âœ… æ”¹è¿› Warmup â†’ ç¨³å®šæ€§

### å·¥ç¨‹ä¼˜åŒ–
8. âœ… AMP (æ··åˆç²¾åº¦) â†’ **2-3Ã— é€Ÿåº¦**
9. âœ… DataLoader ä¼˜åŒ– â†’ 20-40% åŠ é€Ÿ
10. âœ… TTA (å¯é€‰) â†’ +0.5-1%

---

## ğŸ“‚ æ–‡ä»¶æ¸…å•

```
RSST/
â”œâ”€â”€ train_mamba_baseline_v2.py       # â­ V2 è®­ç»ƒè„šæœ¬ï¼ˆæ–°ï¼‰
â”œâ”€â”€ run_mamba_baseline_v2.sh         # â­ V2 å¯åŠ¨è„šæœ¬ï¼ˆæ–°ï¼‰
â”œâ”€â”€ models/mamba.py                  # â­ å·²ä¿®æ”¹ï¼ˆæ”¯æŒ Drop Pathï¼‰
â”œâ”€â”€ Mamba_Baseline_V2_å®Œæ•´ä¼˜åŒ–.md    # è¯¦ç»†æ–‡æ¡£
â”œâ”€â”€ Mamba_Baseline_ä¼˜åŒ–å»ºè®®.md       # ä¼˜åŒ–æ–¹æ¡ˆ
â””â”€â”€ README_Mamba_Baseline_V2.md      # æœ¬æ–‡æ¡£
```

---

## ğŸ“‹ ä¸»è¦ä¿®æ”¹

### 1. `models/mamba.py`
```python
# æ–°å¢ DropPath ç±»
class DropPath(nn.Module): ...

# MambaBlock æ”¯æŒ drop_path
class MambaBlock(nn.Module):
    def __init__(self, ..., drop_path=0.0): ...
    def forward(self, x):
        x = x + self.drop_path(self.ssm(...))  # â­
        x = x + self.drop_path(self.mlp(...))  # â­
```

### 2. `train_mamba_baseline_v2.py`
- âœ… å®Œæ•´å®ç° EMA
- âœ… Layer-wise LR Decay
- âœ… æ··åˆç²¾åº¦è®­ç»ƒ (AMP)
- âœ… AutoAugment + Random Erasing
- âœ… TTA æ”¯æŒ

---

## ğŸ¯ æ ¸å¿ƒå‚æ•°

```bash
--epochs 300              # è®­ç»ƒè½®æ•°
--batch_size 128          # Batch size
--lr 1e-3                 # å­¦ä¹ ç‡
--weight_decay 0.05       # â­ å…³é”®å‚æ•°
--drop_path 0.1           # â­ æ–°å¢
--use_ema                 # â­ å¯ç”¨ EMA
--use_amp                 # â­ å¯ç”¨æ··åˆç²¾åº¦
--use_layerwise_lr        # â­ Layer-wise LR
--use_autoaugment         # â­ AutoAugment
--use_random_erasing      # â­ Random Erasing
```

---

## ğŸ“Š ç›‘æ§è®­ç»ƒ

```bash
# æŸ¥çœ‹æ—¥å¿—
tail -f logs_mamba_baseline_v2/*.log

# æŸ¥çœ‹ GPU
watch -n 1 nvidia-smi

# æŸ¥çœ‹è¿›ç¨‹
ps aux | grep train_mamba_baseline_v2
```

---

## ğŸ”§ å¿«é€Ÿè°ƒä¼˜

### è¿‡æ‹Ÿåˆï¼Ÿ
```bash
--weight_decay 0.08       # å¢å¤§æ­£åˆ™åŒ–
--drop_path 0.15          # å¢å¤§ Drop Path
```

### æ¬ æ‹Ÿåˆï¼Ÿ
```bash
--weight_decay 0.03       # å‡å°æ­£åˆ™åŒ–
--epochs 400              # è®­ç»ƒæ›´ä¹…
```

### è®­ç»ƒä¸ç¨³å®šï¼Ÿ
```bash
--grad_clip 0.5           # æ›´å¼ºæ¢¯åº¦è£å‰ª
--lr 5e-4                 # æ›´å°å­¦ä¹ ç‡
```

---

## ğŸ’¡ ä¸ V1 çš„åŒºåˆ«

| ç‰¹æ€§ | V1 | V2 |
|-----|----|----|
| Drop Path | âŒ | âœ… (0.1) |
| EMA | âŒ | âœ… (0.9999) |
| æ•°æ®å¢å¼º | RandAugment | AutoAugment + Random Erasing |
| å­¦ä¹ ç‡ | ç»Ÿä¸€ LR | Layer-wise LR Decay |
| æ··åˆç²¾åº¦ | âŒ | âœ… AMP |
| Gradient Clip | âŒ | âœ… (1.0) |
| TTA | âŒ | âœ… (å¯é€‰) |
| **CIFAR-10** | 94-95.5% | **97-98%** |
| **CIFAR-100** | 76-81% | **82-86%** |
| **é€Ÿåº¦** | 1.0Ã— | **2-3Ã—** |

---

## ğŸ“ å­¦ä¹ èµ„æº

- **è¯¦ç»†æ–‡æ¡£**: `Mamba_Baseline_V2_å®Œæ•´ä¼˜åŒ–.md`
- **ä¼˜åŒ–æ–¹æ¡ˆ**: `Mamba_Baseline_ä¼˜åŒ–å»ºè®®.md`
- **åŸå§‹ V1**: `train_mamba_baseline.py`

---

## âœ… éªŒè¯æ£€æŸ¥

- [ ] `conda activate structlth`
- [ ] æ•°æ®é›†ï¼š`datasets/cifar10`, `datasets/cifar100`
- [ ] `chmod +x run_mamba_baseline_v2.sh`
- [ ] `nvidia-smi` æ£€æŸ¥ GPU
- [ ] ç¡®è®¤ `models/mamba.py` åŒ…å« `DropPath`

---

## ğŸ‰ ç«‹å³å¼€å§‹

```bash
# 1. è¿›å…¥ç›®å½•
cd /workspace/ycx/RSST

# 2. è¿è¡Œè®­ç»ƒ
./run_mamba_baseline_v2.sh

# 3. ç›‘æ§æ—¥å¿—
tail -f logs_mamba_baseline_v2/*.log
```

---

**é¢„æœŸç»“æœ**:
- ğŸ“ˆ CIFAR-10: **97-98%**
- ğŸ“ˆ CIFAR-100: **82-86%**
- âš¡ è®­ç»ƒæ—¶é—´: **1-1.5 å¤©**ï¼ˆåŒ GPUï¼‰

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼çªç ´ SOTAï¼** ğŸš€
