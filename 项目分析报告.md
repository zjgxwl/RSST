# RSSTé¡¹ç›®è¯¦ç»†åˆ†æžæŠ¥å‘Š

## ä¸€ã€é¡¹ç›®æ¦‚è§ˆ

è¿™æ˜¯ä¸€ä¸ªåŸºäºŽ**è¿­ä»£å‰ªæžï¼ˆIterative Pruningï¼‰**å’Œ**æ­£åˆ™åŒ–ç¨³å®šåŒ–è®­ç»ƒï¼ˆRegularization-based Stabilized Trainingï¼‰**çš„ç¥žç»ç½‘ç»œåŽ‹ç¼©é¡¹ç›®ï¼Œä¸»è¦å®žçŽ°äº†RSSTå’ŒRefillä¸¤ç§å‰ªæžç®—æ³•ã€‚

### æ ¸å¿ƒæ–‡ä»¶ç»“æž„
```
main_imp_fillback.py        # ä¸»è®­ç»ƒè„šæœ¬ï¼ˆå…¥å£ï¼‰
â”œâ”€â”€ model.py                 # ResNetæ¨¡åž‹å®šä¹‰
â”œâ”€â”€ utils.py                 # æ¨¡åž‹å’Œæ•°æ®é›†è®¾ç½®å·¥å…·
â”œâ”€â”€ pruning_utils.py         # å‰ªæžå·¥å…·å‡½æ•°
â”œâ”€â”€ permute_masks.py         # æŽ©ç æŽ’åˆ—å·¥å…·
â””â”€â”€ reg_pruner_files/
    â”œâ”€â”€ reg_pruner.py        # æ­£åˆ™åŒ–å‰ªæžå™¨
    â””â”€â”€ meta_pruner.py       # å…ƒå‰ªæžå™¨åŸºç±»
```

---

## äºŒã€ðŸ”¥ æ¨¡åž‹æ›¿æ¢ä½ç½®è¯¦è§£

### 2.1 ä¸»å…¥å£ï¼š`setup_model_dataset()` å‡½æ•°
**æ–‡ä»¶ä½ç½®ï¼š** `utils.py` (ç¬¬17-133è¡Œ)

è¿™æ˜¯æ•´ä¸ªé¡¹ç›®çš„**æ¨¡åž‹åˆå§‹åŒ–æ ¸å¿ƒ**ï¼Œæ‰€æœ‰æ¨¡åž‹çš„åˆ›å»ºéƒ½åœ¨è¿™é‡Œå®Œæˆã€‚

```python
# utils.py ç¬¬17è¡Œå¼€å§‹
def setup_model_dataset(args):
    # 1. æ ¹æ®æ•°æ®é›†é€‰æ‹©
    if args.dataset == 'cifar10':
        classes = 10
        train_set_loader, val_loader, test_loader = cifar10_dataloaders(...)
    elif args.dataset == 'cifar100':
        classes = 100
        train_set_loader, val_loader, test_loader = cifar100_dataloaders(...)
    elif args.dataset == 'tiny-imagenet':
        classes = 200
        train_set_loader, val_loader, test_loader = tiny_imagenet_dataloaders(...)
    
    # 2. æ ¹æ®æž¶æž„é€‰æ‹©æ¨¡åž‹ â­â­â­ æ¨¡åž‹æ›¿æ¢å…³é”®ä½ç½®
    if args.arch == 'res18':
        model = resnet18(num_classes=classes, ...)
    elif args.arch == 'res20s':  # å½“å‰é»˜è®¤ä½¿ç”¨
        model = resnet20(number_class=classes)
    elif args.arch == 'res50':
        model = resnet50(num_classes=classes, ...)
    elif args.arch == 'vgg16_bn':
        model = vgg16_bn(num_classes=classes, ...)
    elif args.arch == 'mobilenet':
        model = MobileNet(num_classes=classes)
    # ... æ›´å¤šæ¨¡åž‹é€‰é¡¹
    
    # 3. æ·»åŠ å½’ä¸€åŒ–å±‚
    model.normalize = normalization
    
    return model, train_set_loader, val_loader, test_loader
```

### 2.2 å…·ä½“æ¨¡åž‹å®žçŽ°ä½ç½®

| æ¨¡åž‹ç±»åž‹ | å¯¼å…¥è¯­å¥ä½ç½® | å®žé™…æ–‡ä»¶ | ç”¨é€” |
|---------|------------|---------|------|
| `resnet18/50` | utils.py ç¬¬5è¡Œ | `models/resnet.py` | ImageNetè§„æ¨¡çš„ResNet |
| `resnet20/56` | utils.py ç¬¬6è¡Œ | `models/resnets.py` | CIFARæ•°æ®é›†ä¸“ç”¨å°åž‹ResNet |
| `vgg16_bn` | utils.py ç¬¬14è¡Œ | `models/vgg.py` | VGGç½‘ç»œ |
| `mobilenet` | utils.py ç¬¬10è¡Œ | `models/mobilenet.py` | ç§»åŠ¨ç«¯ç½‘ç»œ |
| `densenet161` | utils.py ç¬¬7è¡Œ | `models/densenet.py` | DenseNetç½‘ç»œ |

### 2.3 ä¸»è®­ç»ƒè„šæœ¬ä¸­çš„æ¨¡åž‹åˆå§‹åŒ–
**æ–‡ä»¶ä½ç½®ï¼š** `main_imp_fillback.py` (ç¬¬102è¡Œ)

```python
# main_imp_fillback.py ç¬¬102è¡Œ
model, train_loader, val_loader, test_loader = setup_model_dataset(args)
```

è¿™æ˜¯ä¸»è„šæœ¬è°ƒç”¨æ¨¡åž‹è®¾ç½®å‡½æ•°çš„ä½ç½®ï¼Œé€šè¿‡å‘½ä»¤è¡Œå‚æ•° `--arch` æ¥é€‰æ‹©æ¨¡åž‹ã€‚

### 2.4 å¦‚ä½•æ›¿æ¢è‡ªå·±çš„æ¨¡åž‹ï¼Ÿ

**æ­¥éª¤1ï¼š** åœ¨ `models/` ç›®å½•ä¸‹åˆ›å»ºä½ çš„æ¨¡åž‹æ–‡ä»¶ï¼Œä¾‹å¦‚ `my_model.py`
```python
# models/my_model.py
import torch.nn as nn

class MyCustomModel(nn.Module):
    def __init__(self, num_classes=100):
        super(MyCustomModel, self).__init__()
        # å®šä¹‰ä½ çš„ç½‘ç»œç»“æž„
        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)
        # ... æ›´å¤šå±‚
        self.fc = nn.Linear(512, num_classes)
    
    def forward(self, x):
        # å‰å‘ä¼ æ’­
        return x
```

**æ­¥éª¤2ï¼š** åœ¨ `utils.py` ä¸­å¯¼å…¥å¹¶æ·»åŠ é€‰é¡¹
```python
# utils.py é¡¶éƒ¨æ·»åŠ å¯¼å…¥
from models.my_model import MyCustomModel

# setup_model_dataset() å‡½æ•°ä¸­æ·»åŠ é€‰é¡¹
elif args.arch == 'my_model':
    print('build model: my_custom_model')
    model = MyCustomModel(num_classes=classes)
```

**æ­¥éª¤3ï¼š** è¿è¡Œæ—¶æŒ‡å®šæ¨¡åž‹
```bash
python main_imp_fillback.py --arch my_model --dataset cifar100
```

---

## ä¸‰ã€ðŸ”¥ðŸ”¥ å‰ªæžæ–¹æ³•è¯¦è§£

### 3.1 æ•´ä½“å‰ªæžæµç¨‹

é¡¹ç›®å®žçŽ°äº†**è¿­ä»£å‰ªæžï¼ˆIterative Magnitude Pruning, IMPï¼‰**æ¡†æž¶ï¼Œç»“åˆä¸¤ç§ç®—æ³•ï¼š

1. **Refillç®—æ³•**ï¼šåŸºäºŽé‡è¦æ€§çš„æƒé‡æ¢å¤
2. **RSSTç®—æ³•**ï¼šåŸºäºŽæ­£åˆ™åŒ–çš„æ¸è¿›å¼å‰ªæž

#### 3.1.1 ä¸»å¾ªçŽ¯æµç¨‹å›¾
```
åˆå§‹åŒ–æ¨¡åž‹
    â†“
for state in range(pruning_times):  # é»˜è®¤20æ¬¡è¿­ä»£å‰ªæž
    â”œâ”€ è®­ç»ƒ epochs è½® (120è½®)
    â”‚   â”œâ”€ å‰å‘ä¼ æ’­
    â”‚   â”œâ”€ è®¡ç®—æŸå¤±
    â”‚   â”œâ”€ åå‘ä¼ æ’­
    â”‚   â””â”€ [RSST] åº”ç”¨æ­£åˆ™åŒ–æ¢¯åº¦
    â”‚
    â”œâ”€ æ‰§è¡Œå‰ªæž (pruning_model)
    â”‚   â””â”€ æŒ‰L1èŒƒæ•°å…¨å±€å‰ªæž rate=20%
    â”‚
    â”œâ”€ æå–mask (extract_mask)
    â”‚
    â””â”€ æƒé‡é‡ç½®+å¯é€‰æ¢å¤
        â”œâ”€ [Refill] æŒ‰criteriaæ¢å¤éƒ¨åˆ†æƒé‡
        â””â”€ [RSST] æ ‡è®°å¾…æ­£åˆ™åŒ–æƒé‡
```

### 3.2 æ ¸å¿ƒå‰ªæžç®—æ³•å®žçŽ°

#### 3.2.1 å…¨å±€L1èŒƒæ•°å‰ªæž
**æ–‡ä»¶ä½ç½®ï¼š** `pruning_utils.py` (ç¬¬6-22è¡Œ)

```python
def pruning_model(model, px, conv1=False):
    """
    å…¨å±€éžç»“æž„åŒ–å‰ªæž
    Args:
        model: å¾…å‰ªæžæ¨¡åž‹
        px: å‰ªæžçŽ‡ (ä¾‹å¦‚ 0.2 è¡¨ç¤ºå‰ªæŽ‰20%çš„æƒé‡)
        conv1: æ˜¯å¦å‰ªæžç¬¬ä¸€å±‚å·ç§¯
    """
    print('start unstructured pruning for all conv layers')
    parameters_to_prune = []
    
    # æ”¶é›†æ‰€æœ‰å·ç§¯å±‚çš„æƒé‡
    for name, m in model.named_modules():
        if isinstance(m, nn.Conv2d):
            if (name == 'conv1' and conv1) or (name != 'conv1'):
                parameters_to_prune.append((m, 'weight'))
    
    parameters_to_prune = tuple(parameters_to_prune)
    
    # ä½¿ç”¨PyTorchçš„å…¨å±€L1å‰ªæž
    prune.global_unstructured(
        parameters_to_prune,
        pruning_method=prune.L1Unstructured,  # æŒ‰L1èŒƒæ•°å‰ªæž
        amount=px,  # å‰ªæžæ¯”ä¾‹
    )
```

**è°ƒç”¨ä½ç½®ï¼š** `main_imp_fillback.py` ç¬¬321è¡Œ
```python
pruning_model(model, args.rate, conv1=False)  # args.rate=0.2
```

#### 3.2.2 è‡ªå®šä¹‰æŽ©ç å‰ªæž
**æ–‡ä»¶ä½ç½®ï¼š** `pruning_utils.py` (ç¬¬70-75è¡Œ)

```python
def prune_model_custom(model, mask_dict, conv1=False):
    """
    ä½¿ç”¨è‡ªå®šä¹‰maskè¿›è¡Œå‰ªæž
    """
    for name, m in model.named_modules():
        if isinstance(m, nn.Conv2d):
            if (name == 'conv1' and conv1) or (name != 'conv1'):
                print('pruning layer with custom mask:', name)
                # åº”ç”¨è‡ªå®šä¹‰æŽ©ç 
                prune.CustomFromMask.apply(
                    m, 'weight', 
                    mask=mask_dict[name+'.weight_mask'].to(m.weight.device)
                )
```

### 3.3 Refillç®—æ³•è¯¦è§£
**æ–‡ä»¶ä½ç½®ï¼š** `pruning_utils.py` (ç¬¬77-243è¡Œ)

è¿™æ˜¯ä¸€ä¸ª**æ™ºèƒ½æƒé‡æ¢å¤ç®—æ³•**ï¼Œæ ¹æ®ä¸åŒçš„criteriaé€‰æ‹©æ€§åœ°æ¢å¤è¢«å‰ªæžçš„æƒé‡ã€‚

#### æ ¸å¿ƒæ€æƒ³
åœ¨æ¯è½®å‰ªæžåŽï¼Œæ ¹æ®é‡è¦æ€§æŒ‡æ ‡æ¢å¤ `fillback_rate` æ¯”ä¾‹çš„æƒé‡ã€‚

#### æ”¯æŒçš„criteriaç±»åž‹

```python
def prune_model_custom_fillback(model, mask_dict, criteria="remain", 
                                fillback_rate=0.0, ...):
    """
    Args:
        criteria: æƒé‡æ¢å¤æ ‡å‡†
            - 'remain': ä¿ç•™maskä¸­å‰©ä½™æƒé‡æœ€å¤šçš„é€šé“
            - 'magnitude': æŒ‰è®­ç»ƒåŽæƒé‡çš„L1èŒƒæ•°å¤§å°
            - 'l1': æŒ‰ç‰¹å¾å›¾çš„L1èŒƒæ•°
            - 'l2': æŒ‰ç‰¹å¾å›¾çš„L2èŒƒæ•°
            - 'saliency': æŒ‰æ˜¾è‘—æ€§(ç‰¹å¾å›¾Ã—æ¢¯åº¦)
        fillback_rate: æ¢å¤æ¯”ä¾‹ (0.0-1.0)
    """
```

##### 1. `criteria='magnitude'` (æƒé‡å¹…åº¦)
```python
# pruning_utils.py ç¬¬175-188è¡Œ
elif criteria == 'magnitude':
    mask = mask_dict[name+'.weight_mask']
    # è®¡ç®—æ¯ä¸ªé€šé“çš„æƒé‡ç»å¯¹å€¼ä¹‹å’Œ
    count = trained_weight[name + '.weight'].view(mask.shape[0], -1).abs().sum(1)
    
    if (mask.shape[0] - int_channel) > 0:
        # é€‰æ‹©æƒé‡å’Œæœ€å¤§çš„é€šé“ä¿ç•™
        threshold, _ = torch.kthvalue(count, mask.shape[0] - int_channel)
        mask[torch.where(count > threshold)[0]] = 1
        mask[torch.where(count < threshold)[0]] = 0
```

##### 2. `criteria='l1'` (ç‰¹å¾å›¾L1èŒƒæ•°)
```python
# pruning_utils.py ç¬¬190-201è¡Œ
elif criteria == 'l1':
    mask = mask_dict[name+'.weight_mask']
    # ä½¿ç”¨å‰å‘ä¼ æ’­çš„ç‰¹å¾å›¾
    count = feature_maps[counter].view(mask.shape[0], -1).abs().sum(1)
    threshold, _ = torch.kthvalue(count, mask.shape[0] - int_channel)
    
    mask[torch.where(count > threshold)[0]] = 1
    mask[torch.where(count < threshold)[0]] = 0
```

##### 3. `criteria='saliency'` (æ˜¾è‘—æ€§)
```python
# pruning_utils.py ç¬¬215-226è¡Œ
elif criteria == 'saliency':
    mask = mask_dict[name+'.weight_mask']
    # ç‰¹å¾å›¾ Ã— æ¢¯åº¦
    count = (feature_maps[counter] * 
             torch.autograd.grad(loss, feature_maps[counter], 
                               retain_graph=True, only_inputs=True)[0]
            ).view(mask.shape[0], -1).abs().sum(1)
    
    threshold, _ = torch.kthvalue(count, mask.shape[0] - int_channel)
    mask[torch.where(count > threshold)[0]] = 1
    mask[torch.where(count < threshold)[0]] = 0
```

**è°ƒç”¨ä½ç½®ï¼š** `main_imp_fillback.py` ç¬¬332è¡Œ
```python
if args.struct == 'refill':
    print('æ‰§è¡ŒRefillç®—æ³•')
    model = prune_model_custom_fillback(
        model, 
        mask_dict=current_mask,
        train_loader=train_loader,
        trained_weight=train_weight,
        init_weight=initialization,
        criteria=args.criteria,  # é»˜è®¤'l1'
        fillback_rate=args.fillback_rate,  # é»˜è®¤0.0
        return_mask_only=False
    )
```

### 3.4 RSSTç®—æ³•è¯¦è§£ï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼‰

#### 3.4.1 ç®—æ³•åŽŸç†
**Regularization-based Structure-aware Sparse Training**

æ ¸å¿ƒæ€æƒ³ï¼šå¯¹å³å°†è¢«å‰ªæžä½†å½“å‰ä»ä¿ç•™çš„æƒé‡æ–½åŠ **é€æ¸å¢žå¤§çš„L2æ­£åˆ™åŒ–**ï¼Œä½¿å…¶å¹³æ»‘åœ°è¶‹å‘äºŽ0ï¼Œç„¶åŽå†å‰ªæžã€‚

#### 3.4.2 ä¸‰ä¸ªå…³é”®é˜¶æ®µ

**é˜¶æ®µ1ï¼šæ ‡è®°å¾…æ­£åˆ™åŒ–æƒé‡**
**æ–‡ä»¶ä½ç½®ï¼š** `main_imp_fillback.py` (ç¬¬334-341è¡Œ)

```python
elif args.struct == 'rsst':
    print('æ‰§è¡ŒRSSTç®—æ³•')
    # è¿”å›žrefill mask (æ ‡è®°å“ªäº›æƒé‡éœ€è¦æ­£åˆ™åŒ–)
    mask = prune_model_custom_fillback(
        model, 
        mask_dict=current_mask,      # å½“å‰å‰ªæžmask
        train_loader=train_loader,
        trained_weight=train_weight,
        init_weight=initialization,
        criteria=args.criteria,       # é»˜è®¤'l1'
        fillback_rate=0.0,            # ä¸æ¢å¤æƒé‡
        return_mask_only=True         # åªè¿”å›žmask
    )
    passer.refill_mask = mask  # ä¼ é€’ç»™æ­£åˆ™åŒ–å™¨
```

è¿™ä¸€æ­¥æ‰¾å‡ºï¼š
- `current_mask=1` ä½† `refill_mask=0` çš„æƒé‡
- å³"å½“å‰ä¿ç•™ä½†é‡è¦æ€§ä½Ž"çš„æƒé‡

**é˜¶æ®µ2ï¼šåŠ¨æ€æ›´æ–°æ­£åˆ™åŒ–å¼ºåº¦**
**æ–‡ä»¶ä½ç½®ï¼š** `main_imp_fillback.py` (ç¬¬353-404è¡Œ)

```python
def update_reg(passer, pruner, model, state, i, j):
    """
    i: å½“å‰batchç´¢å¼•
    j: æ€»batchæ•°é‡
    """
    for name, m in model.named_modules():
        if isinstance(m, nn.Conv2d):
            if name != 'conv1':
                refill_mask = passer.refill_mask[name].flatten()
                current_mask = passer.current_mask[name + '.weight_mask'].flatten()
                
                # æ‰¾åˆ°éœ€è¦æ­£åˆ™åŒ–çš„æƒé‡ç´¢å¼•
                # refill_mask=0 ä¸” current_mask=1 çš„æƒé‡
                unpruned_indices = torch.where(
                    (refill_mask == 0) & (current_mask == 1)
                )
                unpruned_indices_np = unpruned_indices[0].data.cpu().numpy()
                
                # æ ¹æ®ä¸åŒçš„scheduleæ›´æ–°æ­£åˆ™åŒ–lambda
                if passer.args.RST_schedule == 'x':
                    # çº¿æ€§å¢žé•¿
                    pruner.reg[name][unpruned_indices_np] += args.reg_granularity_prune
                
                elif passer.args.RST_schedule == 'x^2':
                    # äºŒæ¬¡å¢žé•¿
                    pruner.reg_[name][unpruned_indices_np] += args.reg_granularity_prune
                    pruner.reg[name][unpruned_indices_np] = pruner.reg_[name][unpruned_indices_np] ** 2
                
                elif passer.args.RST_schedule == 'exp':
                    # æŒ‡æ•°å¢žé•¿
                    pruner.reg_[name][unpruned_indices_np] += args.reg_granularity_prune
                    pruner.reg[name][unpruned_indices_np] = torch.tensor(
                        np.exp(pruner.reg_[name][unpruned_indices_np].cpu().numpy())
                    )
                
                elif passer.args.RST_schedule == 'exp_custom_exponents':
                    # è‡ªå®šä¹‰æŒ‡æ•°å¢žé•¿ï¼ˆé»˜è®¤ï¼‰
                    e = math.exp(1)
                    weight_start = (1 / (e - 1) * args.reg_granularity_prune * 
                                  (math.exp((i + 1) ** args.exponents / 
                                           j ** args.exponents) - 1))
                    pruner.reg[name][unpruned_indices_np] = weight_start
```

**è°ƒç”¨æ—¶æœºï¼š** æ¯ä¸ªè®­ç»ƒepochçš„æ¯ä¸ªbatch
```python
# main_imp_fillback.py ç¬¬416-434è¡Œ
def train(state, train_loader, model, criterion, optimizer, epoch, passer, pruner):
    for i, (image, target) in enumerate(train_loader):
        j = len(train_loader)
        
        output_clean = model(image)
        loss = criterion(output_clean, target)
        optimizer.zero_grad()
        loss.backward()
        
        if state > 0 and args.struct == 'rsst':
            # æ›´æ–°æ­£åˆ™åŒ–å¼ºåº¦
            if passer.args.reg_granularity_prune * i < 1:
                update_reg(passer, pruner, model, state, i, j)
            
            # åº”ç”¨æ­£åˆ™åŒ–åˆ°æ¢¯åº¦
            model = apply_reg(pruner, model, passer)
        
        optimizer.step()
```

**é˜¶æ®µ3ï¼šåº”ç”¨æ­£åˆ™åŒ–åˆ°æ¢¯åº¦**
**æ–‡ä»¶ä½ç½®ï¼š** `main_imp_fillback.py` (ç¬¬458-483è¡Œ)

```python
def apply_reg(pruner, model, passer):
    """
    å°†L2æ­£åˆ™åŒ–åº”ç”¨åˆ°æƒé‡æ¢¯åº¦ä¸Š
    """
    print('åº”ç”¨æ­£åˆ™åŒ–åˆ°æ¢¯åº¦')
    for name, m in model.named_modules():
        if name in pruner.reg:
            # èŽ·å–æ­£åˆ™åŒ–å¼ºåº¦ [N, C, H, W]
            reg = pruner.reg[name]
            reg = reg.view_as(m.weight.data)
            
            # è®¡ç®—L2æ­£åˆ™åŒ–æ¢¯åº¦: Î» * w
            l2_grad = reg * m.weight
            
            if passer.args.block_loss_grad:
                # ä»…ä½¿ç”¨æ­£åˆ™åŒ–æ¢¯åº¦
                m.weight.grad = l2_grad
            else:
                # å°†æ­£åˆ™åŒ–æ¢¯åº¦åŠ åˆ°åŽŸæ¢¯åº¦ä¸Š
                m.weight.grad += l2_grad
    
    return model
```

#### 3.4.3 æ­£åˆ™åŒ–Scheduleå¯¹æ¯”

| Schedule | å…¬å¼ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|---------|------|------|---------|
| `x` | Î» = Î»â‚€ + kÃ—Î”Î» | çº¿æ€§å¢žé•¿ | æ¸©å’Œå‰ªæž |
| `x^2` | Î» = (Î»â‚€ + kÃ—Î”Î»)Â² | äºŒæ¬¡å¢žé•¿ | ä¸­ç­‰æ¿€è¿› |
| `x^3` | Î» = (Î»â‚€ + kÃ—Î”Î»)Â³ | ä¸‰æ¬¡å¢žé•¿ | æ¿€è¿›å‰ªæž |
| `exp` | Î» = exp(Î»â‚€ + kÃ—Î”Î») | æŒ‡æ•°å¢žé•¿ | å¿«é€Ÿæ”¶æ•› |
| `exp_custom_exponents` | Î» = (1/(e-1))Ã—Î”Î»Ã—(exp((k+1)â¿/Kâ¿)-1) | å¯æŽ§æŒ‡æ•° | **é»˜è®¤æŽ¨è** |

å‚æ•°è¯´æ˜Žï¼š
- `k`: å½“å‰batchç´¢å¼•
- `K`: æ€»batchæ•°
- `Î”Î»`: `reg_granularity_prune` (é»˜è®¤1.0)
- `n`: `exponents` (é»˜è®¤4)

#### 3.4.4 RSSTå®Œæ•´æµç¨‹å›¾

```
State 0: æ­£å¸¸è®­ç»ƒ120 epochs
    â†“
State 1+:
    â”œâ”€ è®­ç»ƒå¼€å§‹å‰
    â”‚   â””â”€ åˆå§‹åŒ–pruner = reg_pruner.Pruner(model, args, passer)
    â”‚
    â”œâ”€ æ¯ä¸ªepochçš„æ¯ä¸ªbatch:
    â”‚   â”œâ”€ å‰å‘ä¼ æ’­
    â”‚   â”œâ”€ è®¡ç®—loss
    â”‚   â”œâ”€ åå‘ä¼ æ’­
    â”‚   â”œâ”€ update_reg() â† æ›´æ–°æ­£åˆ™åŒ–lambda
    â”‚   â”‚   â””â”€ æ ¹æ®scheduleå¢žå¤§å¾…å‰ªæžæƒé‡çš„lambda
    â”‚   â”œâ”€ apply_reg() â† åº”ç”¨æ­£åˆ™åŒ–
    â”‚   â”‚   â””â”€ weight.grad += lambda * weight
    â”‚   â””â”€ optimizer.step()
    â”‚
    â”œâ”€ è®­ç»ƒåŽï¼ˆç¬¬270-305è¡Œï¼‰
    â”‚   â””â”€ å°†æ­£åˆ™åŒ–çš„æƒé‡é‡ç½®ä¸ºåˆå§‹å€¼
    â”‚
    â””â”€ æ‰§è¡Œå‰ªæž + æ ‡è®°ä¸‹ä¸€è½®å¾…æ­£åˆ™åŒ–æƒé‡
```

### 3.5 å…¶ä»–å‰ªæžæ–¹æ³•

é¡¹ç›®è¿˜å®žçŽ°äº†å¤šç§ç»å…¸å‰ªæžç®—æ³•ï¼ˆåœ¨ `pruning_utils.py` ä¸­ï¼‰ï¼š

| æ–¹æ³• | å‡½æ•°å | è¡Œæ•° | åŽŸç† |
|-----|--------|------|------|
| **SNIP** | `prune_snip` | 270-295 | åŸºäºŽæ¢¯åº¦Ã—æƒé‡çš„æ˜¾è‘—æ€§ |
| **GraSP** | `prune_grasp` | 346-393 | åŸºäºŽæ¢¯åº¦æµçš„Hessianè¿‘ä¼¼ |
| **SynFlow** | `prune_synflow` | 297-344 | åŸºäºŽæ•°æ®æµçš„è¿­ä»£å‰ªæž |
| **OMP** | `prune_omp` | 395-409 | åŸºäºŽæƒé‡å¹…åº¦ |
| **Random** | `prune_rp` | 411-425 | éšæœºå‰ªæžï¼ˆåŸºçº¿ï¼‰ |
| **ADMM** | `prune_admm` | 604-634 | åŸºäºŽäº¤æ›¿æ–¹å‘ä¹˜å­æ³• |

---

## å››ã€å…³é”®å‚æ•°è¯´æ˜Ž

### 4.1 å‰ªæžç›¸å…³å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜Ž | ä½ç½® |
|-----|--------|------|------|
| `--pruning_times` | 20 | è¿­ä»£å‰ªæžæ¬¡æ•° | ç¬¬64è¡Œ |
| `--rate` | 0.2 | æ¯æ¬¡å‰ªæžæ¯”ä¾‹ | ç¬¬65è¡Œ |
| `--prune_type` | 'lt' | å‰ªæžç±»åž‹(lt/pt/rewind_lt) | ç¬¬66è¡Œ |
| `--struct` | 'rsst' | ç®—æ³•é€‰æ‹©(rsst/refill) | ç¬¬74è¡Œ |
| `--fillback_rate` | 0.0 | æƒé‡æ¢å¤æ¯”ä¾‹ | ç¬¬75è¡Œ |
| `--criteria` | 'l1' | é‡è¦æ€§è¯„ä¼°æ ‡å‡† | ç¬¬79è¡Œ |

### 4.2 RSSTç‰¹æœ‰å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜Ž |
|-----|--------|------|
| `--RST_schedule` | 'exp_custom_exponents' | æ­£åˆ™åŒ–å¢žé•¿ç­–ç•¥ |
| `--reg_granularity_prune` | 1.0 | æ­£åˆ™åŒ–å¢žé•¿ç²’åº¦ |
| `--exponents` | 4 | æŒ‡æ•°å‡½æ•°æ›²çŽ‡ |
| `--block_loss_grad` | False | æ˜¯å¦é˜»æ–­ä»»åŠ¡æ¢¯åº¦ |

### 4.3 è®­ç»ƒå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜Ž |
|-----|--------|------|
| `--epochs` | 120 | æ¯è½®è®­ç»ƒepochæ•° |
| `--batch_size` | 3128 | æ‰¹å¤§å° |
| `--lr` | 0.01 | åˆå§‹å­¦ä¹ çŽ‡ |
| `--warmup` | 20 | é¢„çƒ­epochæ•° |
| `--rewind_epoch` | 24 | LTå›žé€€epoch |

---

## äº”ã€å®žéªŒç¤ºä¾‹

### 5.1 è¿è¡ŒRSSTç®—æ³•
```bash
python main_imp_fillback.py \
    --dataset cifar100 \
    --arch res20s \
    --struct rsst \
    --criteria l1 \
    --pruning_times 20 \
    --rate 0.2 \
    --RST_schedule exp_custom_exponents \
    --exponents 4 \
    --reg_granularity_prune 1.0 \
    --epochs 120 \
    --batch_size 128 \
    --lr 0.01
```

### 5.2 è¿è¡ŒRefillç®—æ³•
```bash
python main_imp_fillback.py \
    --dataset cifar100 \
    --arch res20s \
    --struct refill \
    --criteria magnitude \
    --fillback_rate 0.1 \
    --pruning_times 20 \
    --rate 0.2 \
    --epochs 120
```

### 5.3 ä½¿ç”¨ä¸åŒæ¨¡åž‹
```bash
# ä½¿ç”¨ResNet18
python main_imp_fillback.py --arch res18 --dataset tiny-imagenet

# ä½¿ç”¨VGG16
python main_imp_fillback.py --arch vgg16_bn --dataset cifar100

# ä½¿ç”¨MobileNet
python main_imp_fillback.py --arch mobilenet --dataset cifar10
```

---

## å…­ã€æ ¸å¿ƒä»£ç è·¯å¾„å¯¼èˆª

### 6.1 æ¨¡åž‹ç›¸å…³
```
setup_model_dataset()           utils.py:17-133
    â”œâ”€ cifar100_dataloaders()   dataset.py:63-83
    â”œâ”€ resnet20()               models/resnets.py
    â””â”€ normalizeè®¾ç½®            utils.py:129
```

### 6.2 å‰ªæžæµç¨‹
```
main()                          main_imp_fillback.py:83-352
    â”œâ”€ for state in range(pruning_times):
    â”‚   â”œâ”€ train()              ç¬¬406-457è¡Œ
    â”‚   â”‚   â”œâ”€ forward
    â”‚   â”‚   â”œâ”€ backward
    â”‚   â”‚   â”œâ”€ update_reg()     ç¬¬353-404è¡Œ
    â”‚   â”‚   â””â”€ apply_reg()      ç¬¬458-483è¡Œ
    â”‚   â”‚
    â”‚   â”œâ”€ validate()           ç¬¬484-521è¡Œ
    â”‚   â”œâ”€ pruning_model()      pruning_utils.py:6-22
    â”‚   â”œâ”€ extract_mask()       pruning_utils.py:53-58
    â”‚   â””â”€ prune_model_custom_fillback()  pruning_utils.py:77-243
```

### 6.3 æ­£åˆ™åŒ–å‰ªæžå™¨
```
reg_pruner.Pruner               reg_pruner_files/reg_pruner.py
    â”œâ”€ __init__()               ç¬¬11-40è¡Œ (åˆå§‹åŒ–)
    â”œâ”€ _update_reg()            ç¬¬87-139è¡Œ (æ›´æ–°lambda)
    â”œâ”€ apply_reg()              ç¬¬242è¡Œè°ƒç”¨
    â””â”€ prune()                  ç¬¬173-309è¡Œ (ä¸»å¾ªçŽ¯)
```

---

## ä¸ƒã€æƒé‡é‡ç½®æœºåˆ¶

è¿™æ˜¯IMPï¼ˆIterative Magnitude Pruningï¼‰çš„æ ¸å¿ƒç‰¹æ€§ï¼š

```python
# main_imp_fillback.py ç¬¬328è¡Œ
model.load_state_dict(initialization)  # é‡ç½®ä¸ºåˆå§‹æƒé‡

# åˆå§‹åŒ–æƒé‡çš„èŽ·å–ï¼ˆç¬¬131-154è¡Œï¼‰
new_initialization = copy.deepcopy(model.state_dict())
if not os.path.exists(args.init):
    torch.save(new_initialization, args.init)
initialization = torch.load(args.init)
```

è¿™ä¿è¯äº†æ¯è½®å‰ªæžåŽæ¨¡åž‹éƒ½ä»Žç›¸åŒçš„åˆå§‹åŒ–å¼€å§‹è®­ç»ƒï¼Œç¬¦åˆLottery Ticket Hypothesisã€‚

---

## å…«ã€maskç®¡ç†æœºåˆ¶

### 8.1 maskæå–
```python
# pruning_utils.py ç¬¬53-58è¡Œ
def extract_mask(model_dict):
    new_dict = {}
    for key in model_dict.keys():
        if 'mask' in key:
            new_dict[key] = model_dict[key]
    return new_dict
```

### 8.2 maskåº”ç”¨
PyTorchçš„å‰ªæžæœºåˆ¶ä¼šè‡ªåŠ¨åˆ›å»ºï¼š
- `module.weight_orig`: åŽŸå§‹æƒé‡
- `module.weight_mask`: äºŒå€¼mask
- `module.weight`: å®žé™…ä½¿ç”¨çš„æƒé‡ = weight_orig * weight_mask

### 8.3 maskä¼ é€’
```python
# main_imp_fillback.py ç¬¬324-325è¡Œ
current_mask = extract_mask(model.state_dict())
passer.current_mask = current_mask  # ä¼ é€’ç»™passerå¯¹è±¡
```

---

## ä¹ã€WandBæ—¥å¿—è®°å½•

é¡¹ç›®é›†æˆäº†Weights & Biasesè¿›è¡Œå®žéªŒè¿½è¸ªï¼š

```python
# main_imp_fillback.py ç¬¬88-90è¡Œ
wdb_name = '_'.join([args.struct, args.RST_schedule, args.criteria, 
                     args.arch, args.dataset])
wandb.init(project='RSST', entity='609354432', name=wdb_name, 
           config=vars(parser.parse_args()))

# è®°å½•çš„æŒ‡æ ‡
wandb.log({
    'remain_weight': remain_weight,           # å‰©ä½™æƒé‡æ¯”ä¾‹
    'reg_lambd': reg_lambda,                  # æ­£åˆ™åŒ–å¼ºåº¦
    'accuracy': acc,                          # è®­ç»ƒç²¾åº¦
    'val_accuracy': tacc,                     # éªŒè¯ç²¾åº¦
    'test_accuracy': test_tacc,               # æµ‹è¯•ç²¾åº¦
    'prune_times': state                      # å‰ªæžæ¬¡æ•°
})
```

---

## åã€æ€»ç»“

### 10.1 é¡¹ç›®ä¼˜åŠ¿
1. âœ… å®žçŽ°äº†å¤šç§å‰ªæžç®—æ³•ï¼ˆRSST, Refill, SNIP, GraSPç­‰ï¼‰
2. âœ… æ”¯æŒå¤šç§æ¨¡åž‹æž¶æž„ï¼ˆResNet, VGG, MobileNetç­‰ï¼‰
3. âœ… çµæ´»çš„æ­£åˆ™åŒ–scheduleï¼ˆçº¿æ€§ã€æŒ‡æ•°ã€è‡ªå®šä¹‰ï¼‰
4. âœ… å®Œæ•´çš„å®žéªŒè¿½è¸ªï¼ˆWandBé›†æˆï¼‰
5. âœ… æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºŽæ‰©å±•

### 10.2 å…³é”®åˆ›æ–°ç‚¹
- **RSSTç®—æ³•**ï¼šé€šè¿‡æ¸è¿›å¼æ­£åˆ™åŒ–å¹³æ»‘å‰ªæžè¿‡ç¨‹
- **å¤šç§criteria**ï¼šæ”¯æŒmagnitude, l1, l2, saliencyç­‰å¤šç§é‡è¦æ€§è¯„ä¼°
- **çµæ´»çš„schedule**ï¼šå¯æŽ§åˆ¶æ­£åˆ™åŒ–å¢žé•¿æ›²çº¿

### 10.3 ä½¿ç”¨å»ºè®®
1. åˆæ¬¡ä½¿ç”¨å»ºè®®ä»Ž `res20s + cifar100` å¼€å§‹
2. RSSTç®—æ³•é€šå¸¸æ¯”Refillæ•ˆæžœæ›´å¥½
3. `exp_custom_exponents` scheduleé…åˆ `exponents=4` æ˜¯è¾ƒä¼˜é…ç½®
4. è°ƒæ•´ `reg_granularity_prune` å¯ä»¥æŽ§åˆ¶æ­£åˆ™åŒ–å¼ºåº¦

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š** 2026å¹´1æœˆ5æ—¥  
**åˆ†æžæ–‡ä»¶ï¼š** main_imp_fillback.py, pruning_utils.py, utils.py, model.pyç­‰

