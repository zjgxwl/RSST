"""
æµ‹è¯•ViT Head + MLP Neurons ç»„åˆå‰ªæ
éªŒè¯åŒæ—¶å‰ªæattention headså’ŒMLP neuronsçš„åŠŸèƒ½
"""
import torch
import torch.nn as nn
from models.vit import vit_tiny
import vit_pruning_utils
import vit_pruning_utils_head_mlp

def test_head_mlp_combined_pruning():
    print("="*80)
    print("æµ‹è¯•ViT Head + MLP Neurons ç»„åˆå‰ªæ")
    print("="*80)
    
    # åˆ›å»ºæ¨¡å‹
    model = vit_tiny(num_classes=100, img_size=32, pretrained=False).cuda()
    print(f"\nâœ“ åˆ›å»ºViT-Tinyæ¨¡å‹")
    print(f"  - Blocks: 9")
    print(f"  - Heads per block: 3")
    print(f"  - Hidden dim (MLP): 384")
    
    # ç¬¬ä¸€æ­¥ï¼šå…¨å±€L1å‰ªæï¼ˆelement-wiseï¼‰
    print("\n" + "="*80)
    print("ã€æ­¥éª¤1ã€‘å…¨å±€L1å‰ªæ (element-wise, 20%)")
    print("="*80)
    vit_pruning_utils.pruning_model_vit(model, px=0.2, prune_patch_embed=False)
    
    # æå–mask
    current_mask = vit_pruning_utils.extract_mask_vit(model.state_dict())
    print(f"âœ“ æå–åˆ° {len(current_mask)} ä¸ªmask")
    
    # æ£€æŸ¥ç¨€ç–åº¦
    remain_1 = vit_pruning_utils.check_sparsity_vit(model, prune_patch_embed=False)
    
    # ç§»é™¤å‰ªæé‡å‚æ•°åŒ–
    vit_pruning_utils.remove_prune_vit(model, prune_patch_embed=False)
    
    # åˆ›å»ºè®­ç»ƒæ•°æ®ï¼ˆæ¨¡æ‹Ÿï¼‰
    train_loader = [(torch.randn(4, 3, 32, 32).cuda(), torch.randint(0, 100, (4,)).cuda())]
    
    # ä¿å­˜è®­ç»ƒåçš„æƒé‡å’Œåˆå§‹æƒé‡
    trained_weight = {k: v.clone() for k, v in model.state_dict().items()}
    init_weight = {k: v.clone() for k, v in model.state_dict().items()}
    
    # ç¬¬äºŒæ­¥ï¼šHead + MLPç»„åˆå‰ªæ
    print("\n" + "="*80)
    print("ã€æ­¥éª¤2ã€‘Head + MLP Neurons ç»„åˆå‰ªæ")
    print("="*80)
    
    # æµ‹è¯•ä¸åŒçš„criteria
    test_configs = [
        {'criteria': 'remain', 'head_ratio': 0.33, 'mlp_ratio': 0.3},
        {'criteria': 'magnitude', 'head_ratio': 0.33, 'mlp_ratio': 0.3},
        {'criteria': 'l1', 'head_ratio': 0.33, 'mlp_ratio': 0.3},
    ]
    
    for config in test_configs:
        print(f"\n{'â”€'*80}")
        print(f"æµ‹è¯•é…ç½®: criteria={config['criteria']}, "
              f"head_prune={config['head_ratio']}, mlp_prune={config['mlp_ratio']}")
        print(f"{'â”€'*80}")
        
        # è°ƒç”¨Head+MLPç»„åˆå‰ªæ
        refill_mask = vit_pruning_utils_head_mlp.prune_model_custom_fillback_vit_head_and_mlp(
            model=model,
            mask_dict=current_mask,
            train_loader=train_loader,
            trained_weight=trained_weight,
            init_weight=init_weight,
            criteria=config['criteria'],
            head_prune_ratio=config['head_ratio'],
            mlp_prune_ratio=config['mlp_ratio'],
            return_mask_only=True  # RSSTæ¨¡å¼
        )
        
        # éªŒè¯è¿”å›çš„mask
        print(f"\nâœ“ è¿”å› {len(refill_mask)} ä¸ªmask")
        
        # éªŒè¯headçº§åˆ«çš„maskç»“æ„
        head_structured = 0
        for name, mask in refill_mask.items():
            if 'attn.qkv' in name:
                parts = name.split('.')
                block_idx = int(parts[1])
                attn = model.blocks[block_idx].attn
                num_heads = attn.num_heads
                head_dim = attn.head_dim
                
                mask_reshaped = mask.view(3, num_heads, head_dim, -1)
                
                # æ£€æŸ¥æ¯ä¸ªheadæ˜¯å¦æ˜¯å‡†ç»“æ„åŒ–çš„
                for h in range(num_heads):
                    head_mask = mask_reshaped[:, h, :, :]
                    unique_vals = torch.unique(head_mask)
                    
                    if len(unique_vals) == 1:
                        head_structured += 1
        
        # éªŒè¯neuronçº§åˆ«çš„maskç»“æ„
        neuron_structured = 0
        for name, mask in refill_mask.items():
            if 'mlp.fc1' in name:
                # æ£€æŸ¥æ¯ä¸ªneuronï¼ˆè¡Œï¼‰æ˜¯å¦æ˜¯å…¨0æˆ–å…¨1
                for neuron_idx in range(mask.shape[0]):
                    neuron_mask = mask[neuron_idx, :]
                    unique_vals = torch.unique(neuron_mask)
                    
                    if len(unique_vals) == 1:
                        neuron_structured += 1
        
        print(f"\néªŒè¯ç»“æœ:")
        print(f"  âœ“ Headçº§åˆ«å‡†ç»“æ„åŒ–: {head_structured} heads")
        print(f"  âœ“ Neuronçº§åˆ«å‡†ç»“æ„åŒ–: {neuron_structured} neurons")
        
        # éªŒè¯maskç»´åº¦åŒ¹é…
        dimension_match = True
        for name in refill_mask.keys():
            mask_key = name + '.weight_mask'
            if mask_key in current_mask:
                if refill_mask[name].shape != current_mask[mask_key].shape:
                    dimension_match = False
                    print(f"  âœ— ç»´åº¦ä¸åŒ¹é…: {name}")
        
        if dimension_match:
            print(f"  âœ“ æ‰€æœ‰maskç»´åº¦åŒ¹é…")
        
        print(f"\nâœ“ criteria={config['criteria']} æµ‹è¯•å®Œæˆ")
    
    # ç¬¬ä¸‰æ­¥ï¼šæ¨¡æ‹ŸRSSTçš„update_reg
    print("\n" + "="*80)
    print("ã€æ­¥éª¤3ã€‘æ¨¡æ‹ŸRSSTçš„update_regï¼ˆæ‰¾å‡ºéœ€è¦æ­£åˆ™åŒ–çš„æƒé‡ï¼‰")
    print("="*80)
    
    # ä½¿ç”¨magnitude criteriaç”Ÿæˆä¸€ä¸ªrefill_mask
    refill_mask = vit_pruning_utils_head_mlp.prune_model_custom_fillback_vit_head_and_mlp(
        model=model,
        mask_dict=current_mask,
        train_loader=train_loader,
        trained_weight=trained_weight,
        init_weight=init_weight,
        criteria='magnitude',
        head_prune_ratio=0.33,
        mlp_prune_ratio=0.3,
        return_mask_only=True
    )
    
    print("\næ¨¡æ‹Ÿupdate_regæ‰¾å‡ºéœ€è¦æ­£åˆ™åŒ–çš„æƒé‡:")
    
    # æ£€æŸ¥å‰2ä¸ªattnå±‚å’Œå‰2ä¸ªmlpå±‚
    checked_count = 0
    for name in list(refill_mask.keys())[:4]:
        if 'attn.qkv' in name or 'mlp.fc1' in name:
            mask_key = name + '.weight_mask'
            if mask_key in current_mask:
                refill_mask_flat = refill_mask[name].flatten()
                current_mask_flat = current_mask[mask_key].flatten()
                
                # æ‰¾å‡ºéœ€è¦æ­£åˆ™åŒ–çš„ç´¢å¼•
                unpruned_indices = torch.where((refill_mask_flat == 0) & (current_mask_flat == 1))[0]
                
                print(f"\n  {name}:")
                print(f"    - Total weights: {refill_mask_flat.numel()}")
                print(f"    - Refill mask=0: {(refill_mask_flat == 0).sum().item()}")
                print(f"    - Current mask=1: {(current_mask_flat == 1).sum().item()}")
                print(f"    - Need regularization: {len(unpruned_indices)} weights")
                
                checked_count += 1
                if checked_count >= 4:
                    break
    
    print("\n" + "="*80)
    print("âœ“ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    print("="*80)
    print("\næ€»ç»“:")
    print("  1. âœ“ å…¨å±€L1å‰ªæï¼ˆelement-wiseï¼‰æ­£å¸¸")
    print("  2. âœ“ Head + MLPç»„åˆå‰ªææ­£å¸¸")
    print("  3. âœ“ æ‰€æœ‰criteriaéƒ½æ”¯æŒ")
    print("  4. âœ“ Headçº§åˆ«å’ŒNeuronçº§åˆ«éƒ½æ˜¯å‡†ç»“æ„åŒ–çš„")
    print("  5. âœ“ Maskç»´åº¦åŒ¹é…ï¼Œå¯ç”¨äºæ­£åˆ™åŒ–")
    print("\nğŸ‘ Head + MLPç»„åˆå‰ªæå®ç°æ­£ç¡®ï¼Œå…¼å®¹RSSTçš„æ¸è¿›å¼è¿­ä»£ï¼")
    
    print("\n" + "="*80)
    print("å‹ç¼©æ•ˆæœé¢„ä¼°:")
    print("="*80)
    
    # ç»Ÿè®¡å‹ç¼©æ•ˆæœ
    total_attn_params = 0
    total_mlp_params = 0
    pruned_attn_params = 0
    pruned_mlp_params = 0
    
    for name, mask in refill_mask.items():
        if 'attn' in name:
            total_attn_params += mask.numel()
            pruned_attn_params += (mask == 0).sum().item()
        elif 'mlp' in name:
            total_mlp_params += mask.numel()
            pruned_mlp_params += (mask == 0).sum().item()
    
    attn_sparsity = 100 * pruned_attn_params / total_attn_params if total_attn_params > 0 else 0
    mlp_sparsity = 100 * pruned_mlp_params / total_mlp_params if total_mlp_params > 0 else 0
    overall_sparsity = 100 * (pruned_attn_params + pruned_mlp_params) / (total_attn_params + total_mlp_params)
    
    print(f"  Attentionéƒ¨åˆ†:")
    print(f"    - æ€»å‚æ•°: {total_attn_params:,}")
    print(f"    - å‰ªæå‚æ•°: {pruned_attn_params:,}")
    print(f"    - ç¨€ç–åº¦: {attn_sparsity:.2f}%")
    
    print(f"\n  MLPéƒ¨åˆ†:")
    print(f"    - æ€»å‚æ•°: {total_mlp_params:,}")
    print(f"    - å‰ªæå‚æ•°: {pruned_mlp_params:,}")
    print(f"    - ç¨€ç–åº¦: {mlp_sparsity:.2f}%")
    
    print(f"\n  æ€»ä½“:")
    print(f"    - æ€»å‚æ•°: {total_attn_params + total_mlp_params:,}")
    print(f"    - å‰ªæå‚æ•°: {pruned_attn_params + pruned_mlp_params:,}")
    print(f"    - ç¨€ç–åº¦: {overall_sparsity:.2f}%")
    
    compression_ratio = 1 / (1 - overall_sparsity/100)
    print(f"    - å‹ç¼©ç‡: {compression_ratio:.2f}x")

if __name__ == '__main__':
    test_head_mlp_combined_pruning()
